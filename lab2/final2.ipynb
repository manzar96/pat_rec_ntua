{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Βήμα 9:</b><br>\n",
    "Στο βήμα αυτό χρησιμοποιήσαμε τη συνάρτηση που μας δόθηκε για να διαβάσουμε τα αρχεία από το dataset στο https://github.com/Jakobovski/free-spoken-digit-dataset. Αλλάξαμε στη γραμμή 11, την εντολή <b>f.split('/')[5]</b> από την <b>f.split('/')[1]</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def parser(directory):\n",
    "    # Parse relevant dataset info\n",
    "    files = glob(os.path.join(directory, '*.wav'))\n",
    "    fnames = [f.split('/')[5].split('.')[0].split('_') for f in files]\n",
    "    ids = [f[2] for f in fnames]\n",
    "    y = [int(f[0]) for f in fnames]\n",
    "    speakers = [f[1] for f in fnames]\n",
    "    _, Fs = librosa.core.load(files[0], sr=None)\n",
    "\n",
    "    def read_wav(f):\n",
    "        global Fs\n",
    "        wav, fs = librosa.core.load(f, sr=None)\n",
    "        return wav\n",
    "\n",
    "    # Read all wavs\n",
    "    wavs = [read_wav(f) for f in files]\n",
    "\n",
    "    # Extract MFCCs for all wavs\n",
    "    window = 30 * Fs // 1000\n",
    "    step = window // 2\n",
    "    frames = [librosa.feature.mfcc(wav, Fs, n_fft=window, hop_length=window - step, n_mfcc=6).T for wav in wavs]\n",
    "    # Print dataset info\n",
    "    print('Total wavs: {}'.format(len(frames)))\n",
    "\n",
    "    # Standardize data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(np.concatenate(frames))\n",
    "    for i in range(len(frames)):\n",
    "        frames[i] = scaler.transform(frames[i])\n",
    "\n",
    "    # Split to train-test\n",
    "    X_train, y_train, spk_train = [], [], []\n",
    "    X_test, y_test, spk_test = [], [], []\n",
    "    test_indices = ['0', '1', '2', '3', '4']\n",
    "    for idx, frame, label, spk in zip(ids, frames, y, speakers):\n",
    "        if str(idx) in test_indices:\n",
    "            X_test.append(frame)\n",
    "            y_test.append(label)\n",
    "            spk_test.append(spk)\n",
    "        else:\n",
    "            X_train.append(frame)\n",
    "            y_train.append(label)\n",
    "            spk_train.append(spk)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, spk_train, spk_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total wavs: 1500\n"
     ]
    }
   ],
   "source": [
    "# Reading the wavs with given parser.py function\n",
    "(X_train_set, X_test_set, y_train_set, y_test_set, spk_train, spk_test) = parser(\"/home/manzar/Desktop/recordings/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα θα χωρίσουμε το dataset σε train και test δεδομενα ώστε το split να είναι <b>stratified</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the test set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_set, y_train_set, stratify=y_train_set, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pomegranate import *\n",
    "\n",
    "\n",
    "def create_GMM_HMM_models(X,Y,No_states,No_mixtures):\n",
    "    my_GMMHMM_models=[]\n",
    "\n",
    "    #se auti tin ilopioisi pernw ola ta idia psifia kai ta kanw afou prwta parw ta means tous meta ta kanw concatenate\n",
    "\n",
    "    \n",
    "    \n",
    "    #se auti tin ilopioisi pernw ola ta idia psifia kai ta kanw concatenate\n",
    "    for d in range(0,10):\n",
    "        data_features=[]\n",
    "        k=0\n",
    "        for index,data in enumerate(Y):\n",
    "            if data==d:\n",
    "                if k==0:\n",
    "                    concatenated_features = X[index] #create for each digit an array with the features of each window concatenated in vertical axis.\n",
    "                    k+=1\n",
    "                else:\n",
    "                    concatenated_features = np.concatenate((concatenated_features,X[index]),axis=0)\n",
    "                data_features.append(X[index].tolist())\n",
    "                \n",
    "        \n",
    "        print(d)\n",
    "        #print(concatenated_features.shape)\n",
    "        #print(len(data_features[0][0]))\n",
    "       \n",
    "        \n",
    "        \n",
    "            \n",
    "        dists = [] # list of probability distributions for the HMM states\n",
    "        n_states = No_states# the number of HMM states\n",
    "        n_mixtures = No_mixtures # the number of Gaussians\n",
    "        gmm = True # whether to use GMM or plain Gaussian\n",
    "\n",
    "\n",
    "        for i in range(n_states):\n",
    "            if gmm:\n",
    "                a = GeneralMixtureModel.from_samples(MultivariateGaussianDistribution, n_mixtures, concatenated_features)\n",
    "            else:\n",
    "                a = MultivariateGaussianDistribution.from_samples(concatenated_features)\n",
    "            dists.append(a)\n",
    "\n",
    "        #initialize transition matrix\n",
    "        trans_mat = np.zeros([n_states,n_states]) # your transition matrix\n",
    "\n",
    "        for i in range(0,n_states):\n",
    "            if i==n_states-1:\n",
    "                trans_mat[i][i]=1    \n",
    "            else:\n",
    "                trans_mat[i][i]=0.5\n",
    "                trans_mat[i][i+1]=0.5\n",
    "\n",
    "        #print(trans_mat)\n",
    "        #initialize start prob matrix and end prob matrix\n",
    "        starts = [1]+[0]*(n_states-1)\n",
    "        ends = [0]*(n_states-1)+[1]\n",
    "        \n",
    "        #print(trans_mat)\n",
    "        #print(starts)\n",
    "        #print(ends)\n",
    "        #transition_mat = np.asarray(transition_mat) # your transition matrix\n",
    "        #starts = np.asarray(starts) # your starting probability matrix\n",
    "        #ends = np.asarray(ends)  # your ending probability matrix\n",
    "\n",
    "\n",
    "        \n",
    "        data = data_features # your data: must be a Python list that contains: 2D lists with the sequences (so its dimension would be num_sequences x seq_length x feature_dimension)\n",
    "                  # But be careful, it is not a numpy array, it is a Python list (so each sequence can have different length)\n",
    "\n",
    "\n",
    "        # Define the GMM-HMM\n",
    "        model = HiddenMarkovModel.from_matrix(trans_mat, dists, starts, ends, state_names=['s{}'.format(i) for i in range(n_states)])\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(data_features,max_iterations=5)\n",
    "\n",
    "        #print(model)\n",
    "        my_GMMHMM_models.append(model)\n",
    "        \n",
    "    return my_GMMHMM_models\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Επιλέγουμε 2 gaussian mixture models και 4 hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "models=create_GMM_HMM_models(X_train,y_train,4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Predict a sequence\n",
    "sample = X_val[1] # a sample sequence\n",
    "\n",
    "log_probs = []\n",
    "\n",
    "for model in models:\n",
    "    logp, _ = model.viterbi(sample) # Run viterbi algorithm and return log-probability\n",
    "    log_probs.append(logp)\n",
    "    \n",
    "    \n",
    "digit_pred=np.argmax(log_probs)\n",
    "print(digit_pred)\n",
    "print(y_val[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vima 13: ipologismos confussion matrix gia validation set kai test set kai antistoixwn accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9629629629629629\n",
      "Confusion matrix, without normalization\n",
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 27  0  0  0  0  0  0  0  0]\n",
      " [ 1  0 26  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 25  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 27  0  0  0  0  0]\n",
      " [ 0  1  0  0  0 24  0  1  0  1]\n",
      " [ 0  0  0  0  0  0 27  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 27  0  0]\n",
      " [ 0  0  0  1  0  0  1  1 24  0]\n",
      " [ 0  1  0  0  0  0  0  0  0 26]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_val=np.zeros([len(np.unique(y_val)),len(np.unique(y_val))])\n",
    "accuracy_val=0;\n",
    "\n",
    "for sample,label in zip(X_val,y_val):\n",
    "    \n",
    "    log_probs=[]\n",
    "    for model in models:\n",
    "        \n",
    "        logp, _ = model.viterbi(sample) # Run viterbi algorithm and return log-probability\n",
    "        log_probs.append(logp)\n",
    "    digit_pred=np.argmax(log_probs)\n",
    "    confusion_val[label][digit_pred] +=1\n",
    "    if label==digit_pred:\n",
    "        accuracy_val+=1\n",
    "#print(confusion_val)\n",
    "accuracy_val = accuracy_val / len(X_val)\n",
    "print(accuracy_val)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_confusion_matrix(confusion_val.astype(int),[0,1,2,3,4,5,6,7,8,9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n",
      "Confusion matrix, without normalization\n",
      "[[15  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 15  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  0  1  0  0  0]\n",
      " [ 0  0  0 15  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 15  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 15  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 15  0  0]\n",
      " [ 0  0  0  2  0  0  1  0 12  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 15]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "confusion_test=np.zeros([len(np.unique(y_test_set)),len(np.unique(y_test_set))])\n",
    "accuracy_test=0;\n",
    "\n",
    "for sample,label in zip(X_test_set,y_test_set):\n",
    "    log_probs=[]\n",
    "    for model in models:\n",
    "        logp, _ = model.viterbi(sample) # Run viterbi algorithm and return log-probability\n",
    "        log_probs.append(logp)\n",
    "    digit_pred=np.argmax(log_probs)\n",
    "    confusion_test[label][digit_pred] +=1\n",
    "    if label==digit_pred:\n",
    "        accuracy_test+=1\n",
    "\n",
    "accuracy_test = accuracy_test / len(X_test_set)\n",
    "\n",
    "print(accuracy_test)\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_confusion_matrix(confusion_test.astype(int),[0,1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Βήμα 14:\n",
    "Σε αυτό το βήμα υλοποιούμε ένα baseline lstm.. και στην συνέχεια κάνουμε διάφορες παραλλαγές αυτού."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class FrameLevelDataset(Dataset):\n",
    "    def __init__(self, feats, labels):\n",
    "        \"\"\"\n",
    "            feats: Python list of numpy arrays that contain the sequence features.\n",
    "                   Each element of this list is a numpy array of shape seq_length x feature_dimension\n",
    "            labels: Python list that contains the label for each sequence (each label must be an integer)\n",
    "        \"\"\"\n",
    "        #store length of each element sequence\n",
    "        self.lengths =  [element.shape[0] for element in feats]\n",
    "\n",
    "        self.feats = self.zero_pad_and_stack(feats)\n",
    "        if isinstance(labels, (list, tuple)):\n",
    "            self.labels = np.array(labels).astype('int64')\n",
    "            \n",
    "\n",
    "    def zero_pad_and_stack(self, x):\n",
    "        \"\"\"\n",
    "            This function performs zero padding on a list of features and forms them into a numpy 3D array\n",
    "            returns\n",
    "                padded: a 3D numpy array of shape num_sequences x max_sequence_length x feature_dimension\n",
    "        \"\"\"\n",
    "        padded = []\n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        max_sequence_length = max(self.lengths)\n",
    "        for index,instance in enumerate(x):\n",
    "            if self.lengths[index] < max_sequence_length:\n",
    "                zero_features = np.zeros( (max_sequence_length-self.lengths[index], instance.shape[1]))\n",
    "                padded.append(np.concatenate((instance,zero_features),axis=0))\n",
    "            else:\n",
    "                padded.append(instance)\n",
    "        padded = np.asarray(padded)\n",
    "        return padded\n",
    "    \n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.feats[item], self.labels[item], self.lengths[item]\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feats)\n",
    "    \n",
    "from torch.autograd import Variable\n",
    "class Variational_LockedDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, features, dropout=0.5):\n",
    "        if not self.training or not dropout:\n",
    "            return features\n",
    "        else:\n",
    "            m = features.data.new(features.size(0), 1, features.size(2)).bernoulli(1-dropout)\n",
    "            print(m.shape)\n",
    "            #we have make mask for all instances in batch and for each feature input vector. Now, we have to apply\n",
    "            #the same mask in each time-step (same mask in the whole sequnce).So we extend the mask matrix\n",
    "            #to all time-steps.\n",
    "            mask = Variable(m, requires_grad=False) / (1 - dropout)\n",
    "            #Extend mask matrix to be the same for each time-step.\n",
    "            mask = mask.expand_as(features)\n",
    "            #we can check that for 2 different time-steps(for specific instance and input) we have the same masks. \n",
    "            print(mask[0][1])\n",
    "            print(mask[0][152])\n",
    "            return mask*features\n",
    "\n",
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, input_dim,rnn_size, output_dim, num_layers,dropout_type=None,dropout=0, bidirectional=False):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size\n",
    "        self.dropout=dropout\n",
    "        '''\n",
    "        if dropout_type is not None:\n",
    "            if dropout_type = 'Variational_Locked_Dropout'\n",
    "            self.dropout = Variational_LockedDropout(dropout=dropout_prob)\n",
    "        '''\n",
    "            \n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        # Initialize the LSTM, Dropout, Output layers\n",
    "        \n",
    "        \n",
    "        #for non-bidirectional:\n",
    "        #we assume that rnn-size is the number of lstm-units...\n",
    "        #input_dim is the vector that each unit will receive as input..\n",
    "        #hidden_dim at basic lstm is the same as hidden_dim...\n",
    "        #so we have...\n",
    "        self.num_layers=num_layers\n",
    "        self.hidden_dim = rnn_size # OR self.hidden_dim = self.feature_size\n",
    "        if self.bidirectional:\n",
    "            self.lstm = nn.LSTM(input_dim,self.hidden_dim//2,num_layers=num_layers,bidirectional=bidirectional,\n",
    "                                dropout=self.dropout,batch_first=True)\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(input_dim,self.hidden_dim,num_layers=num_layers,bidirectional=bidirectional,\n",
    "                                dropout=self.dropout,batch_first=True)\n",
    "\n",
    "        #using batch_first=True affects only the input!\n",
    "        # if the input is at form seq_len,batch,features batch_first=True is not needed\n",
    "        \n",
    "        #self.hidden = self.init_hidden() #initialize hidden state(and cell state)\n",
    "        \n",
    "        #use a linear transformation from lstm hidden_state space to ouput space..\n",
    "        #for digit classification we want to classify a sequence to 0-9 digits. So we will use as output dim the number 10.\n",
    "        self.output_set_size = output_dim\n",
    "        self.hidden2output = nn.Linear(self.hidden_dim,self.output_set_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\" \n",
    "            x : 3D numpy array of dimension N x L x D\n",
    "                N: batch index\n",
    "                L: sequence index\n",
    "                D: feature index\n",
    "\n",
    "            lengths: N x 1\n",
    "         \"\"\"\n",
    "        \n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        \n",
    "        # You must have all of the outputs of the LSTM, but you need only the last one (that does not exceed the sequence length)\n",
    "        # To get it use the last_timestep method\n",
    "        # Then pass it through the remaining network \n",
    "        lstm_out,_ = self.lstm(x)\n",
    "        last_lstm_out = self.last_timestep(lstm_out,lengths)   \n",
    "        out_space = self.hidden2output(last_lstm_out)\n",
    "        return out_space\n",
    "\n",
    "    def last_timestep(self, outputs, lengths, bidirectional=False):\n",
    "        \"\"\"\n",
    "            Returns the last output of the LSTM taking into account the zero padding\n",
    "        \"\"\"\n",
    "        if self.bidirectional:\n",
    "            forward, backward = self.split_directions(outputs)\n",
    "            last_forward = self.last_by_index(forward, lengths)\n",
    "            last_backward = backward[:, 0, :]\n",
    "            # Concatenate and return - maybe add more functionalities like average\n",
    "            return torch.cat((last_forward, last_backward), dim=-1)\n",
    "\n",
    "        else:\n",
    "            return self.last_by_index(outputs, lengths)\n",
    "\n",
    "    @staticmethod\n",
    "    def split_directions(outputs):\n",
    "        direction_size = int(outputs.size(-1) / 2)\n",
    "        forward = outputs[:, :, :direction_size]\n",
    "        backward = outputs[:, :, direction_size:]\n",
    "        return forward, backward\n",
    "\n",
    "    @staticmethod\n",
    "    def last_by_index(outputs, lengths):\n",
    "        # Index of the last output for each sequence.\n",
    "        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),\n",
    "                                               outputs.size(2)).unsqueeze(1)\n",
    "        return outputs.gather(1, idx).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[elem for elem in X_train] \n",
    "train=FrameLevelDataset(samples,y_train)\n",
    "\n",
    "\n",
    "samples=[elem for elem in X_val] \n",
    "val=FrameLevelDataset(samples,y_val)\n",
    "\n",
    "samples=[elem for elem in X_test_set] \n",
    "test=FrameLevelDataset(samples,y_test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SZ=16\n",
    "\n",
    "train_batches = DataLoader(train,batch_size=BATCH_SZ,shuffle=True,num_workers=4)\n",
    "val_batches = DataLoader(val,batch_size=BATCH_SZ,shuffle=True,num_workers=4)\n",
    "test_batches = DataLoader(test,batch_size=BATCH_SZ,shuffle=True,num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SZ=6\n",
    "NUM_CLASSES=10\n",
    "NUM_LAYERS=1\n",
    "HIDDEN_SIZE=20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ekpaideusi kai tautoxrona apotimisi sto validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t \t Training Loss 2.2332704803522896\n",
      "Epoch: 0 \t  \t Validation Loss 2.1471177129184498\n",
      "Epoch: 1 \t \t Training Loss 1.981798817129696\n",
      "Epoch: 1 \t  \t Validation Loss 1.809194522745469\n",
      "Epoch: 2 \t \t Training Loss 1.6263350826852463\n",
      "Epoch: 2 \t  \t Validation Loss 1.5217591944862814\n",
      "Epoch: 3 \t \t Training Loss 1.3819452015792622\n",
      "Epoch: 3 \t  \t Validation Loss 1.2923992311253267\n",
      "Epoch: 4 \t \t Training Loss 1.2144383902058882\n",
      "Epoch: 4 \t  \t Validation Loss 1.1661964409491594\n",
      "Epoch: 5 \t \t Training Loss 1.0818723115850897\n",
      "Epoch: 5 \t  \t Validation Loss 1.0301334086586447\n",
      "Epoch: 6 \t \t Training Loss 0.9763844539137447\n",
      "Epoch: 6 \t  \t Validation Loss 0.9601730108261108\n",
      "Epoch: 7 \t \t Training Loss 0.8726866118171636\n",
      "Epoch: 7 \t  \t Validation Loss 0.9623648454161251\n",
      "Epoch: 8 \t \t Training Loss 0.785246771048097\n",
      "Epoch: 8 \t  \t Validation Loss 0.7189336138613084\n",
      "Epoch: 9 \t \t Training Loss 0.6899191649521098\n",
      "Epoch: 9 \t  \t Validation Loss 0.6796991509549758\n",
      "Epoch: 10 \t \t Training Loss 0.6146121467737591\n",
      "Epoch: 10 \t  \t Validation Loss 0.7506589346072253\n",
      "Epoch: 11 \t \t Training Loss 0.5500450754428611\n",
      "Epoch: 11 \t  \t Validation Loss 0.5997696290997898\n",
      "Epoch: 12 \t \t Training Loss 0.5187006110654158\n",
      "Epoch: 12 \t  \t Validation Loss 0.5040816840003518\n",
      "Epoch: 13 \t \t Training Loss 0.5769307269331287\n",
      "Epoch: 13 \t  \t Validation Loss 0.5356004956890555\n",
      "Epoch: 14 \t \t Training Loss 0.43801745202611475\n",
      "Epoch: 14 \t  \t Validation Loss 0.6502931118011475\n",
      "Epoch: 15 \t \t Training Loss 0.4033115845831001\n",
      "Epoch: 15 \t  \t Validation Loss 0.4117315201198353\n",
      "Epoch: 16 \t \t Training Loss 0.3776859941289705\n",
      "Epoch: 16 \t  \t Validation Loss 0.44537287950515747\n",
      "Epoch: 17 \t \t Training Loss 0.26718047984382687\n",
      "Epoch: 17 \t  \t Validation Loss 0.3462471387842122\n",
      "Epoch: 18 \t \t Training Loss 0.4130728729069233\n",
      "Epoch: 18 \t  \t Validation Loss 0.34776800783241496\n",
      "Epoch: 19 \t \t Training Loss 0.5805618427693844\n",
      "Epoch: 19 \t  \t Validation Loss 0.577282973948647\n",
      "Epoch: 20 \t \t Training Loss 0.3922030632110203\n",
      "Epoch: 20 \t  \t Validation Loss 0.36452143507845264\n",
      "Epoch: 21 \t \t Training Loss 0.3004206423373783\n",
      "Epoch: 21 \t  \t Validation Loss 0.3586064743645051\n",
      "Epoch: 22 \t \t Training Loss 0.21635891497135162\n",
      "Epoch: 22 \t  \t Validation Loss 0.39303303203162027\n",
      "Epoch: 23 \t \t Training Loss 0.1749150330091224\n",
      "Epoch: 23 \t  \t Validation Loss 0.32692965163904075\n",
      "Epoch: 24 \t \t Training Loss 0.24623033908360145\n",
      "Epoch: 24 \t  \t Validation Loss 0.37491507740581737\n",
      "Epoch: 25 \t \t Training Loss 0.1778626165845815\n",
      "Epoch: 25 \t  \t Validation Loss 0.24657539848019094\n",
      "Epoch: 26 \t \t Training Loss 0.14153911173343658\n",
      "Epoch: 26 \t  \t Validation Loss 0.24870092049241066\n",
      "Epoch: 27 \t \t Training Loss 0.14935364880982568\n",
      "Epoch: 27 \t  \t Validation Loss 0.25335897154667797\n",
      "Epoch: 28 \t \t Training Loss 0.10670661663307864\n",
      "Epoch: 28 \t  \t Validation Loss 0.22618575306499705\n",
      "Epoch: 29 \t \t Training Loss 0.10556970777757027\n",
      "Epoch: 29 \t  \t Validation Loss 0.22576934427899473\n",
      "Epoch: 30 \t \t Training Loss 0.09839427471160889\n",
      "Epoch: 30 \t  \t Validation Loss 0.21507785469293594\n",
      "Epoch: 31 \t \t Training Loss 0.09003200184772997\n",
      "Epoch: 31 \t  \t Validation Loss 0.2092751420157797\n",
      "Epoch: 32 \t \t Training Loss 0.0872122077819179\n",
      "Epoch: 32 \t  \t Validation Loss 0.2087523525252062\n",
      "Epoch: 33 \t \t Training Loss 0.08494007412125082\n",
      "Epoch: 33 \t  \t Validation Loss 0.20600952032734365\n",
      "Epoch: 34 \t \t Training Loss 0.08347730426227346\n",
      "Epoch: 34 \t  \t Validation Loss 0.20688645629321828\n"
     ]
    }
   ],
   "source": [
    "model=BasicLSTM(INPUT_SZ,HIDDEN_SIZE,NUM_CLASSES,NUM_LAYERS,bidirectional=False)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "EPOCHS=35\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "    #always necessary. So we comment the following line.\n",
    "    #with torch.autograd(): \n",
    "    model.train()\n",
    "    scheduler.step()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    #train model in each epoch\n",
    "    for index,instance in enumerate(train_batches):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        features,labels,lengths=instance     \n",
    "        features = features.type(torch.FloatTensor)\n",
    "     \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction_vec = model(features,lengths)\n",
    "        #print(prediction_vec.shape)\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(prediction_vec,labels)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))\n",
    "\n",
    "    #we set torch no grad for deactivating autograd engine as we are in evaluation mode and there is no need of computing\n",
    "    # gradients...(It will reduce memory usage and speed up computations but we won’t be able to backpropagate! )\n",
    "    #In evaluation we dont backprop!\n",
    "    with torch.no_grad():\n",
    "        #model.eval() will notify all our layers that we are in eval mode, that way, batchnorm or dropout layers will work\n",
    "        #in eval mode instead of training mode! (dropout will be set to 0 as we dont want to deactivate units during eval)\n",
    "        model.eval()\n",
    "\n",
    "        # evaluate model in each epoch\n",
    "        running_average_loss = 0\n",
    "        acc = 0\n",
    "        n_samples = 0\n",
    "        for index, instance in enumerate(val_batches):\n",
    "\n",
    "            features, labels ,lengths = instance\n",
    "            features = features.type(torch.FloatTensor)\n",
    "            out = model(features,lengths)\n",
    "            loss = loss_function(out,labels)\n",
    "\n",
    "            running_average_loss += loss.detach().item()\n",
    "            \n",
    "        print(\"Epoch: {} \\t  \\t Validation Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Συνολική αποτίμηση στο test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for validation set:  0.92\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "acc = 0\n",
    "n_samples = 0\n",
    "with torch.no_grad():\n",
    "    for index, batch in enumerate(test_batches):\n",
    "        instances, labels ,lengths = batch\n",
    "        instances = instances.type(torch.FloatTensor)\n",
    "        out = model(instances,lengths)\n",
    "        out_scores = F.log_softmax(out,dim=1)\n",
    "        value, y_pred = out_scores.max(1)\n",
    "        \n",
    "        acc += (labels == y_pred).sum().detach().item()\n",
    "        n_samples += instances.shape[0]\n",
    "\n",
    "print(\"Score for validation set: \" ,acc / n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Σε αυτό το βήμα υλοποιούμε early stopping και checkpoints και στο επόμενο θα δοκιμάσουμε διάφορα μοντέλα με χρήση dropout,L2 regularization kai biderectional lstm.Χρησιμοποιούμε early stopping και checkpoints για να γλυτώσουμε χρονο κατα την εκπαίδευση και για να αποφύγουμε overfitting. Τα checkpoints κρατάνε προηγούμενες καταστάσεις του μοντέλου μου τις οποίες μπορουμε να φορτώσουμε."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Trainer_with_Checkpoints():\n",
    "    def __init__(self,validate_every,metrics,max_epochs,patience=10):\n",
    "    \n",
    "        self.validate_every=validate_every\n",
    "        self.metrics = metrics\n",
    "        self.patience=patience\n",
    "        self.best_score=None\n",
    "        self.max_epochs = max_epochs\n",
    "        \n",
    "        \n",
    "    def validate_accuracy(self,mymodel,validation_batches):\n",
    "        with torch.no_grad():\n",
    "            mymodel.eval()\n",
    "            num_correct=0\n",
    "            num_samples=0\n",
    "            with torch.no_grad():\n",
    "                for index, instance in enumerate(validation_batches):\n",
    "                    features, labels ,lengths = instance\n",
    "                    features = features.type(torch.FloatTensor)\n",
    "                    #mymodel.hidden = mymodel.init_hidden(features.shape[0])\n",
    "                    out = mymodel(features,lengths)\n",
    "                    out_scores = F.log_softmax(out,dim=1)\n",
    "                    value, y_pred = out_scores.max(1)\n",
    "\n",
    "                    num_correct += (labels == y_pred).sum().detach().item()\n",
    "                    num_samples += features.shape[0]\n",
    "\n",
    "                print(\"Score for validation set: \" ,num_correct / num_samples)\n",
    "        return num_correct/num_samples\n",
    "\n",
    "    \n",
    "    def checkpoint(self,mymodel,myoptimizer,epoch,checkpointdir,myscheduler=None):\n",
    "        \n",
    "        #if myscheduler is not None:\n",
    "         #   state = {'epoch': epoch + 1,'state_dict': mymodel.state_dict(),\n",
    "       #              'optim_dict' : myoptimizer.state_dict(),'scheduler_dict' : myscheduler.state_dict()}\n",
    "        #else:\n",
    "        #    state = {'epoch': epoch + 1,'state_dict': mymodel.state_dict(),'optim_dict' : myoptimizer.state_dict()}\n",
    "        \n",
    "        #utils.save_checkpoint(state,checkpoint=self.checkpointdir) # path to folder\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': mymodel.state_dict(),\n",
    "            'optimizer_state_dict': myoptimizer.state_dict(),\n",
    "            'scheduler_state_dict': myscheduler.state_dict(),\n",
    "            }, checkpointdir)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def train_model(self,mymodel,myoptimizer,myloss_function,training_batches,validation_batches,\n",
    "                    checkpointdir,myscheduler=None):\n",
    "        \n",
    "        self.best_score=None\n",
    "        counter =0\n",
    "\n",
    "        if self.patience < 1:\n",
    "            raise ValueError(\"Argument patience should be positive integer\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        for epoch in range(self.max_epochs):\n",
    "            #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "            #always necessary. So we comment the following line.\n",
    "            #with torch.autograd(): \n",
    "            mymodel.train()\n",
    "\n",
    "            if myscheduler is not None:\n",
    "                myscheduler.step()\n",
    "\n",
    "            running_average_loss = 0\n",
    "\n",
    "\n",
    "            #train model in each epoch\n",
    "            for index,instance in enumerate(training_batches):\n",
    "                # Step 1. Remember that Pytorch accumulates gradients.\n",
    "                # We need to clear them out before each instance\n",
    "                features,labels,lengths=instance     \n",
    "                features = features.type(torch.FloatTensor)\n",
    "                myoptimizer.zero_grad()\n",
    "                prediction_vec = mymodel(features,lengths)\n",
    "                myloss = myloss_function(prediction_vec,labels)\n",
    "                myloss.backward(retain_graph=True)\n",
    "                myoptimizer.step()\n",
    "                running_average_loss += myloss.detach().item()\n",
    "                if index % 50 == 0:\n",
    "                    print(\"Epoch: {} \\t Batch: {} \\t Training Loss {}\".format(epoch, index, float(running_average_loss) / (index + 1)))\n",
    "               \n",
    "            if epoch==self.max_epochs-1:\n",
    "                print(\"yyyyyeaaaaahhhh\")\n",
    "                if 'accuracy' in self.metrics:\n",
    "                    score = self.validate_accuracy(mymodel,validation_batches)\n",
    "\n",
    "                if self.best_score is None:\n",
    "                    self.best_score = score\n",
    "                    self.checkpoint(mymodel,myoptimizer,epoch,checkpointdir,myscheduler)\n",
    "                    print(\"checkpoint done!\")\n",
    "                    \n",
    "                elif score < self.best_score:\n",
    "                    counter += 1\n",
    "                    if counter >= self.patience:\n",
    "                        print(\"EarlyStopping: Stop training\")\n",
    "                        return\n",
    "                else:\n",
    "                    #found better state in our model\n",
    "                    self.best_score = score\n",
    "                    counter = 0\n",
    "                    #checkpoint\n",
    "                    self.checkpoint(mymodel,myoptimizer,epoch,checkpointdir,myscheduler)\n",
    "                    print(\"checkpoint done!\")\n",
    "            \n",
    "            if epoch % self.validate_every == 0:\n",
    "                if 'accuracy' in self.metrics:\n",
    "                    score = self.validate_accuracy(mymodel,validation_batches)\n",
    "\n",
    "                if self.best_score is None:\n",
    "                    self.best_score = score\n",
    "                    #checkpoint\n",
    "                    self.checkpoint(mymodel,myoptimizer,epoch,checkpointdir,myscheduler)\n",
    "                    print(\"checkpoint done!\")\n",
    "                    \n",
    "                elif score < self.best_score:\n",
    "                    counter += 1\n",
    "                    if counter >= self.patience:\n",
    "                        print(\"EarlyStopping: Stop training\")\n",
    "                        return\n",
    "                    \n",
    "                else:\n",
    "                    #found better state in our model\n",
    "                    self.best_score = score\n",
    "                    counter = 0\n",
    "                    #checkpoint\n",
    "                    self.checkpoint(mymodel,myoptimizer,epoch,checkpointdir,myscheduler)\n",
    "                    print(\"checkpoint done!\")\n",
    "        \n",
    "               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t Batch: 0 \t Training Loss 2.2479171752929688\n",
      "Epoch: 0 \t Batch: 50 \t Training Loss 2.2642657803554163\n",
      "Score for validation set:  0.26666666666666666\n",
      "checkpoint done!\n",
      "Epoch: 1 \t Batch: 0 \t Training Loss 2.153886318206787\n",
      "Epoch: 1 \t Batch: 50 \t Training Loss 2.0857058225893508\n",
      "Epoch: 2 \t Batch: 0 \t Training Loss 1.9879462718963623\n",
      "Epoch: 2 \t Batch: 50 \t Training Loss 1.8181033414952896\n",
      "Epoch: 3 \t Batch: 0 \t Training Loss 1.7510266304016113\n",
      "Epoch: 3 \t Batch: 50 \t Training Loss 1.5337430238723755\n",
      "Epoch: 4 \t Batch: 0 \t Training Loss 1.5207887887954712\n",
      "Epoch: 4 \t Batch: 50 \t Training Loss 1.3249897933473773\n",
      "Epoch: 5 \t Batch: 0 \t Training Loss 1.1543538570404053\n",
      "Epoch: 5 \t Batch: 50 \t Training Loss 1.155113027376287\n",
      "Score for validation set:  0.48518518518518516\n",
      "checkpoint done!\n",
      "Epoch: 6 \t Batch: 0 \t Training Loss 1.3605644702911377\n",
      "Epoch: 6 \t Batch: 50 \t Training Loss 1.072583870560515\n",
      "Epoch: 7 \t Batch: 0 \t Training Loss 0.9405754804611206\n",
      "Epoch: 7 \t Batch: 50 \t Training Loss 0.9536492333692663\n",
      "Epoch: 8 \t Batch: 0 \t Training Loss 0.7347270250320435\n",
      "Epoch: 8 \t Batch: 50 \t Training Loss 0.8917922926884071\n",
      "Epoch: 9 \t Batch: 0 \t Training Loss 0.8804610371589661\n",
      "Epoch: 9 \t Batch: 50 \t Training Loss 0.7515279159826391\n",
      "Epoch: 10 \t Batch: 0 \t Training Loss 0.6991003751754761\n",
      "Epoch: 10 \t Batch: 50 \t Training Loss 0.6430245427524343\n",
      "Score for validation set:  0.8185185185185185\n",
      "checkpoint done!\n",
      "Epoch: 11 \t Batch: 0 \t Training Loss 0.4819524884223938\n",
      "Epoch: 11 \t Batch: 50 \t Training Loss 0.5294412830296684\n",
      "Epoch: 12 \t Batch: 0 \t Training Loss 0.28560319542884827\n",
      "Epoch: 12 \t Batch: 50 \t Training Loss 0.465538855861215\n",
      "Epoch: 13 \t Batch: 0 \t Training Loss 0.4834136962890625\n",
      "Epoch: 13 \t Batch: 50 \t Training Loss 0.4362894886848973\n",
      "Epoch: 14 \t Batch: 0 \t Training Loss 0.5044208765029907\n",
      "Epoch: 14 \t Batch: 50 \t Training Loss 0.5173709214318032\n",
      "Epoch: 15 \t Batch: 0 \t Training Loss 0.1087874174118042\n",
      "Epoch: 15 \t Batch: 50 \t Training Loss 0.32920463032582226\n",
      "Score for validation set:  0.8777777777777778\n",
      "checkpoint done!\n",
      "Epoch: 16 \t Batch: 0 \t Training Loss 0.2039170265197754\n",
      "Epoch: 16 \t Batch: 50 \t Training Loss 0.394124134498484\n",
      "Epoch: 17 \t Batch: 0 \t Training Loss 0.6324319243431091\n",
      "Epoch: 17 \t Batch: 50 \t Training Loss 0.3540402174580331\n",
      "Epoch: 18 \t Batch: 0 \t Training Loss 0.42410504817962646\n",
      "Epoch: 18 \t Batch: 50 \t Training Loss 0.27055779099464417\n",
      "Epoch: 19 \t Batch: 0 \t Training Loss 0.16887685656547546\n",
      "Epoch: 19 \t Batch: 50 \t Training Loss 0.18453661396222956\n",
      "Epoch: 20 \t Batch: 0 \t Training Loss 0.08140745759010315\n",
      "Epoch: 20 \t Batch: 50 \t Training Loss 0.22221096619671465\n",
      "Score for validation set:  0.9407407407407408\n",
      "checkpoint done!\n",
      "Epoch: 21 \t Batch: 0 \t Training Loss 0.12139660120010376\n",
      "Epoch: 21 \t Batch: 50 \t Training Loss 0.2049182738159217\n",
      "Epoch: 22 \t Batch: 0 \t Training Loss 0.09451529383659363\n",
      "Epoch: 22 \t Batch: 50 \t Training Loss 0.16843246420224509\n",
      "Epoch: 23 \t Batch: 0 \t Training Loss 0.18393763899803162\n",
      "Epoch: 23 \t Batch: 50 \t Training Loss 0.1447579039662492\n",
      "Epoch: 24 \t Batch: 0 \t Training Loss 0.17910778522491455\n",
      "Epoch: 24 \t Batch: 50 \t Training Loss 0.139643828366317\n",
      "Epoch: 25 \t Batch: 0 \t Training Loss 0.18589569628238678\n",
      "Epoch: 25 \t Batch: 50 \t Training Loss 0.16162392526280647\n",
      "Score for validation set:  0.937037037037037\n",
      "Epoch: 26 \t Batch: 0 \t Training Loss 0.358147531747818\n",
      "Epoch: 26 \t Batch: 50 \t Training Loss 0.171259093226171\n",
      "Epoch: 27 \t Batch: 0 \t Training Loss 0.3289537727832794\n",
      "Epoch: 27 \t Batch: 50 \t Training Loss 0.17897123974912307\n",
      "Epoch: 28 \t Batch: 0 \t Training Loss 0.26582083106040955\n",
      "Epoch: 28 \t Batch: 50 \t Training Loss 0.10688929610392627\n",
      "Epoch: 29 \t Batch: 0 \t Training Loss 0.0797918438911438\n",
      "Epoch: 29 \t Batch: 50 \t Training Loss 0.09663903596354466\n",
      "Epoch: 30 \t Batch: 0 \t Training Loss 0.038868069648742676\n",
      "Epoch: 30 \t Batch: 50 \t Training Loss 0.12038777301124498\n",
      "Score for validation set:  0.9481481481481482\n",
      "checkpoint done!\n",
      "Epoch: 31 \t Batch: 0 \t Training Loss 0.07751697301864624\n",
      "Epoch: 31 \t Batch: 50 \t Training Loss 0.10177547674553067\n",
      "Epoch: 32 \t Batch: 0 \t Training Loss 0.02727833390235901\n",
      "Epoch: 32 \t Batch: 50 \t Training Loss 0.09768087051662744\n",
      "Epoch: 33 \t Batch: 0 \t Training Loss 0.1846274435520172\n",
      "Epoch: 33 \t Batch: 50 \t Training Loss 0.08759765969771965\n",
      "Epoch: 34 \t Batch: 0 \t Training Loss 0.04647707939147949\n",
      "Epoch: 34 \t Batch: 50 \t Training Loss 0.08508006497925404\n",
      "Epoch: 35 \t Batch: 0 \t Training Loss 0.03548327088356018\n",
      "Epoch: 35 \t Batch: 50 \t Training Loss 0.08316104230927486\n",
      "Score for validation set:  0.9555555555555556\n",
      "checkpoint done!\n",
      "Epoch: 36 \t Batch: 0 \t Training Loss 0.04377853870391846\n",
      "Epoch: 36 \t Batch: 50 \t Training Loss 0.07310092624496012\n",
      "Epoch: 37 \t Batch: 0 \t Training Loss 0.03702825307846069\n",
      "Epoch: 37 \t Batch: 50 \t Training Loss 0.07577414781439538\n",
      "Epoch: 38 \t Batch: 0 \t Training Loss 0.09730669856071472\n",
      "Epoch: 38 \t Batch: 50 \t Training Loss 0.07608149624338337\n",
      "Epoch: 39 \t Batch: 0 \t Training Loss 0.09089663624763489\n",
      "Epoch: 39 \t Batch: 50 \t Training Loss 0.07654060949297513\n",
      "Epoch: 40 \t Batch: 0 \t Training Loss 0.03661239147186279\n",
      "Epoch: 40 \t Batch: 50 \t Training Loss 0.0742053442141589\n",
      "Score for validation set:  0.9518518518518518\n",
      "Epoch: 41 \t Batch: 0 \t Training Loss 0.022350311279296875\n",
      "Epoch: 41 \t Batch: 50 \t Training Loss 0.07163517118669023\n",
      "Epoch: 42 \t Batch: 0 \t Training Loss 0.03010314702987671\n",
      "Epoch: 42 \t Batch: 50 \t Training Loss 0.06924924838776682\n",
      "Epoch: 43 \t Batch: 0 \t Training Loss 0.23389548063278198\n",
      "Epoch: 43 \t Batch: 50 \t Training Loss 0.07374913493792216\n",
      "Epoch: 44 \t Batch: 0 \t Training Loss 0.02359148859977722\n",
      "Epoch: 44 \t Batch: 50 \t Training Loss 0.07315313699198704\n",
      "Epoch: 45 \t Batch: 0 \t Training Loss 0.051555901765823364\n",
      "Epoch: 45 \t Batch: 50 \t Training Loss 0.06355943574624903\n",
      "Score for validation set:  0.9518518518518518\n",
      "Epoch: 46 \t Batch: 0 \t Training Loss 0.03634047508239746\n",
      "Epoch: 46 \t Batch: 50 \t Training Loss 0.061719286091187424\n",
      "Epoch: 47 \t Batch: 0 \t Training Loss 0.027318328619003296\n",
      "Epoch: 47 \t Batch: 50 \t Training Loss 0.06607131630766626\n",
      "Epoch: 48 \t Batch: 0 \t Training Loss 0.043550848960876465\n",
      "Epoch: 48 \t Batch: 50 \t Training Loss 0.05597359438737234\n",
      "Epoch: 49 \t Batch: 0 \t Training Loss 0.016678273677825928\n",
      "Epoch: 49 \t Batch: 50 \t Training Loss 0.06154301149003646\n",
      "Epoch: 50 \t Batch: 0 \t Training Loss 0.02517983317375183\n",
      "Epoch: 50 \t Batch: 50 \t Training Loss 0.05297659921879862\n",
      "Score for validation set:  0.9555555555555556\n",
      "checkpoint done!\n",
      "Epoch: 51 \t Batch: 0 \t Training Loss 0.018563449382781982\n",
      "Epoch: 51 \t Batch: 50 \t Training Loss 0.06541902966359082\n",
      "Epoch: 52 \t Batch: 0 \t Training Loss 0.11118996143341064\n",
      "Epoch: 52 \t Batch: 50 \t Training Loss 0.058277386076310105\n",
      "Epoch: 53 \t Batch: 0 \t Training Loss 0.019780844449996948\n",
      "Epoch: 53 \t Batch: 50 \t Training Loss 0.05481391327053893\n",
      "Epoch: 54 \t Batch: 0 \t Training Loss 0.024260878562927246\n",
      "Epoch: 54 \t Batch: 50 \t Training Loss 0.06375842468411315\n",
      "Epoch: 55 \t Batch: 0 \t Training Loss 0.020978927612304688\n",
      "Epoch: 55 \t Batch: 50 \t Training Loss 0.0573813704883351\n",
      "Score for validation set:  0.9518518518518518\n",
      "Epoch: 56 \t Batch: 0 \t Training Loss 0.12564712762832642\n",
      "Epoch: 56 \t Batch: 50 \t Training Loss 0.05855852686891369\n",
      "Epoch: 57 \t Batch: 0 \t Training Loss 0.029651552438735962\n",
      "Epoch: 57 \t Batch: 50 \t Training Loss 0.057066053444263985\n",
      "Epoch: 58 \t Batch: 0 \t Training Loss 0.027610450983047485\n",
      "Epoch: 58 \t Batch: 50 \t Training Loss 0.06315236757783328\n",
      "Epoch: 59 \t Batch: 0 \t Training Loss 0.018934667110443115\n",
      "Epoch: 59 \t Batch: 50 \t Training Loss 0.06189100648842606\n",
      "yyyyyeaaaaahhhh\n",
      "Score for validation set:  0.9518518518518518\n"
     ]
    }
   ],
   "source": [
    "VALIDATE_EVERY=5\n",
    "METRICS='accuracy'\n",
    "MAX_EPOCHS=60\n",
    "PATIENCE=3\n",
    "INPUT_SZ=6\n",
    "NUM_CLASSES=10\n",
    "NUM_LAYERS=1\n",
    "HIDDEN_SIZE=20\n",
    "\n",
    "CHECKDIR='/home/manzar/Desktop/examino9/protipa/lab2/patrec/lab_2/checkpoints/model1.pt'\n",
    "model=BasicLSTM(INPUT_SZ,HIDDEN_SIZE,NUM_CLASSES,NUM_LAYERS,bidirectional=False)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "\n",
    "trainer = Trainer_with_Checkpoints(validate_every=VALIDATE_EVERY,metrics=METRICS,max_epochs=MAX_EPOCHS,patience=PATIENCE)\n",
    "\n",
    "trainer.train_model(mymodel=model,myoptimizer=optimizer,myloss_function=loss_function,training_batches=train_batches,\n",
    "                    validation_batches=val_batches,checkpointdir=CHECKDIR,myscheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρακάτω εφαρμόζουμε τις ζητούμενες τεχνικές. Ωστόσο δεν προλάβαμε να τις τρέξουμε για την αναφορά. Παρακαλούμε τρέξτε τις.Έχουν δοκιμαστεί προηγουμένως."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(CHECKDIR)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "acc = 0\n",
    "n_samples = 0\n",
    "with torch.no_grad():\n",
    "    for index, batch in enumerate(test_batches):\n",
    "        instances, labels ,lengths = batch\n",
    "        instances = instances.type(torch.FloatTensor)\n",
    "        out = model(instances,lengths)\n",
    "        out_scores = F.log_softmax(out,dim=1)\n",
    "        value, y_pred = out_scores.max(1)\n",
    "        \n",
    "        acc += (labels == y_pred).sum().detach().item()\n",
    "        n_samples += instances.shape[0]\n",
    "\n",
    "print(\"Score for validation set: \" ,acc / n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATE_EVERY=5\n",
    "METRICS='accuracy'\n",
    "MAX_EPOCHS=60\n",
    "PATIENCE=3\n",
    "INPUT_SZ=6\n",
    "NUM_CLASSES=10\n",
    "NUM_LAYERS=1\n",
    "HIDDEN_SIZE=20\n",
    "\n",
    "CHECKDIR='/home/manzar/Desktop/examino9/protipa/lab2/patrec/lab_2/checkpoints/model2_bidir.pt'\n",
    "model=BasicLSTM(INPUT_SZ,HIDDEN_SIZE,NUM_CLASSES,NUM_LAYERS,bidirectional=True)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "\n",
    "trainer.train_model(mymodel=model,myoptimizer=optimizer,myloss_function=loss_function,training_batches=train_batches,\n",
    "                    validation_batches=val_batches,checkpointdir=CHECKDIR,myscheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/home/manzar/Desktop/examino9/protipa/lab2/patrec/lab_2/checkpoints/model2_bidir.pt')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "acc = 0\n",
    "n_samples = 0\n",
    "with torch.no_grad():\n",
    "    for index, batch in enumerate(test_batches):\n",
    "        instances, labels ,lengths = batch\n",
    "        instances = instances.type(torch.FloatTensor)\n",
    "        out = model(instances,lengths)\n",
    "        out_scores = F.log_softmax(out,dim=1)\n",
    "        value, y_pred = out_scores.max(1)\n",
    "        \n",
    "        acc += (labels == y_pred).sum().detach().item()\n",
    "        n_samples += instances.shape[0]\n",
    "\n",
    "print(\"Score for validation set: \" ,acc / n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATE_EVERY=5\n",
    "METRICS='accuracy'\n",
    "MAX_EPOCHS=60\n",
    "PATIENCE=3\n",
    "\n",
    "INPUT_SZ=6\n",
    "NUM_CLASSES=10\n",
    "NUM_LAYERS=2\n",
    "HIDDEN_SIZE=20\n",
    "\n",
    "CHECKDIR='/home/manzar/Desktop/examino9/protipa/lab2/patrec/lab_2/checkpoints/model3_.pt'\n",
    "model = BasicLSTM(INPUT_SZ,HIDDEN_SIZE,NUM_CLASSES,NUM_LAYERS,dropout=0.4,bidirectional=False)\n",
    "loss_function  = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1,weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "trainer.train_model(mymodel=model,myoptimizer=optimizer,myloss_function=loss_function,training_batches=train_batches,\n",
    "                    validation_batches=val_batches,checkpointdir=CHECKDIR,myscheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/home/manzar/Desktop/examino9/protipa/lab2/patrec/lab_2/checkpoints/model3_.pt')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "acc = 0\n",
    "n_samples = 0\n",
    "with torch.no_grad():\n",
    "    for index, batch in enumerate(test_batches):\n",
    "        instances, labels ,lengths = batch\n",
    "        instances = instances.type(torch.FloatTensor)\n",
    "        out = model(instances,lengths)\n",
    "        out_scores = F.log_softmax(out,dim=1)\n",
    "        value, y_pred = out_scores.max(1)\n",
    "        \n",
    "        acc += (labels == y_pred).sum().detach().item()\n",
    "        n_samples += instances.shape[0]\n",
    "\n",
    "print(\"Score for validation set: \" ,acc / n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATE_EVERY=5\n",
    "METRICS='accuracy'\n",
    "MAX_EPOCHS=60\n",
    "PATIENCE=3\n",
    "\n",
    "INPUT_SZ=6\n",
    "NUM_CLASSES=10\n",
    "NUM_LAYERS=2\n",
    "HIDDEN_SIZE=20\n",
    "\n",
    "CHECKDIR='/home/manzar/Desktop/examino9/protipa/lab2/patrec/lab_2/checkpoints/model4_.pt'\n",
    "model = BasicLSTM(INPUT_SZ,HIDDEN_SIZE,NUM_CLASSES,NUM_LAYERS,bidirectional=True)\n",
    "loss_function  = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "\n",
    "\n",
    "trainer.train_model(mymodel=model,myoptimizer=optimizer,myloss_function=loss_function,training_batches=train_batches,\n",
    "                    validation_batches=val_batches,checkpointdir=CHECKDIR,myscheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/home/manzar/Desktop/examino9/protipa/lab2/patrec/lab_2/checkpoints/model4_.pt')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "acc = 0\n",
    "n_samples = 0\n",
    "with torch.no_grad():\n",
    "    for index, batch in enumerate(test_batches):\n",
    "        instances, labels ,lengths = batch\n",
    "        instances = instances.type(torch.FloatTensor)\n",
    "        out = model(instances,lengths)\n",
    "        out_scores = F.log_softmax(out,dim=1)\n",
    "        value, y_pred = out_scores.max(1)\n",
    "        \n",
    "        acc += (labels == y_pred).sum().detach().item()\n",
    "        n_samples += instances.shape[0]\n",
    "\n",
    "print(\"Score for validation set: \" ,acc / n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Υλοποίηση με packed padded sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class FrameLevelDataset(Dataset):\n",
    "    def __init__(self, feats, labels):\n",
    "        \"\"\"\n",
    "            feats: Python list of numpy arrays that contain the sequence features.\n",
    "                   Each element of this list is a numpy array of shape seq_length x feature_dimension\n",
    "            labels: Python list that contains the label for each sequence (each label must be an integer)\n",
    "        \"\"\"\n",
    "        #store length of each element sequence\n",
    "        self.lengths =  [element.shape[0] for element in feats]\n",
    "\n",
    "        self.feats = self.zero_pad_and_stack(feats)\n",
    "        if isinstance(labels, (list, tuple)):\n",
    "            self.labels = np.array(labels).astype('int64')\n",
    "            \n",
    "\n",
    "    def zero_pad_and_stack(self, x):\n",
    "        \"\"\"\n",
    "            This function performs zero padding on a list of features and forms them into a numpy 3D array\n",
    "            returns\n",
    "                padded: a 3D numpy array of shape num_sequences x max_sequence_length x feature_dimension\n",
    "        \"\"\"\n",
    "        padded = []\n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        max_sequence_length = max(self.lengths)\n",
    "        for index,instance in enumerate(x):\n",
    "            if self.lengths[index] < max_sequence_length:\n",
    "                zero_features = np.zeros( (max_sequence_length-self.lengths[index], instance.shape[1]))\n",
    "                padded.append(np.concatenate((instance,zero_features),axis=0))\n",
    "            else:\n",
    "                padded.append(instance)\n",
    "        padded = np.asarray(padded)\n",
    "        return padded\n",
    "    \n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.feats[item], self.labels[item], self.lengths[item]\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feats)\n",
    "    \n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, input_dim,rnn_size, output_dim, num_layers,dropout_type=None,dropout=0, bidirectional=False):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        #self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size\n",
    "        self.dropout=dropout\n",
    "        '''\n",
    "        if dropout_type is not None:\n",
    "            if dropout_type = 'Variational_Locked_Dropout'\n",
    "            self.dropout = Variational_LockedDropout(dropout=dropout_prob)\n",
    "        '''\n",
    "            \n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        # Initialize the LSTM, Dropout, Output layers\n",
    "        \n",
    "        \n",
    "        #for non-bidirectional:\n",
    "        #we assume that rnn-size is the number of lstm-units...\n",
    "        #input_dim is the vector that each unit will receive as input..\n",
    "        #hidden_dim at basic lstm is the same as hidden_dim...\n",
    "        #so we have...\n",
    "        self.num_layers=num_layers\n",
    "        self.hidden_dim = rnn_size # OR self.hidden_dim = self.feature_size\n",
    "        if self.bidirectional:\n",
    "            self.lstm = nn.LSTM(input_dim,self.hidden_dim//2,num_layers=num_layers,bidirectional=bidirectional,\n",
    "                                dropout=self.dropout,batch_first=True)\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(input_dim,self.hidden_dim,num_layers=num_layers,bidirectional=bidirectional,\n",
    "                                dropout=self.dropout,batch_first=True)\n",
    "\n",
    "        #using batch_first=True affects only the input!\n",
    "        # if the input is at form seq_len,batch,features batch_first=True is not needed\n",
    "        \n",
    "        #self.hidden = self.init_hidden() #initialize hidden state(and cell state)\n",
    "        \n",
    "        #use a linear transformation from lstm hidden_state space to ouput space..\n",
    "        #for digit classification we want to classify a sequence to 0-9 digits. So we will use as output dim the number 10.\n",
    "        self.output_set_size = output_dim\n",
    "        self.hidden2output = nn.Linear(self.hidden_dim,self.output_set_size)\n",
    "\n",
    "    def forward(self,x,lengths):\n",
    "        \"\"\" \n",
    "            x : 3D numpy array of dimension N x L x D\n",
    "                N: batch index\n",
    "                L: sequence index\n",
    "                D: feature index\n",
    "\n",
    "            lengths: N x 1\n",
    "         \"\"\"\n",
    "        \n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        \n",
    "        # You must have all of the outputs of the LSTM, but you need only the last one (that does not exceed the sequence length)\n",
    "        # To get it use the last_timestep method\n",
    "        # Then pass it through the remaining network \n",
    "        packedinput = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        packed_output,_ = self.lstm(packedinput)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        output2 = self.last_timestep(output,lengths)\n",
    "        out_space = self.hidden2output(output2)\n",
    "        return out_space\n",
    "\n",
    "    def last_timestep(self, outputs, lengths, bidirectional=False):\n",
    "        \"\"\"\n",
    "            Returns the last output of the LSTM taking into account the zero padding\n",
    "        \"\"\"\n",
    "        if self.bidirectional:\n",
    "            forward, backward = self.split_directions(outputs)\n",
    "            last_forward = self.last_by_index(forward, lengths)\n",
    "            last_backward = backward[:, 0, :]\n",
    "            # Concatenate and return - maybe add more functionalities like average\n",
    "            return torch.cat((last_forward, last_backward), dim=-1)\n",
    "\n",
    "        else:\n",
    "            return self.last_by_index(outputs, lengths)\n",
    "\n",
    "    @staticmethod\n",
    "    def split_directions(outputs):\n",
    "        direction_size = int(outputs.size(-1) / 2)\n",
    "        forward = outputs[:, :, :direction_size]\n",
    "        backward = outputs[:, :, direction_size:]\n",
    "        return forward, backward\n",
    "\n",
    "    @staticmethod\n",
    "    def last_by_index(outputs, lengths):\n",
    "        # Index of the last output for each sequence.\n",
    "        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),\n",
    "                                               outputs.size(2)).unsqueeze(1)\n",
    "        return outputs.gather(1, idx).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[elem for elem in X_train] \n",
    "train=FrameLevelDataset(samples,y_train)\n",
    "\n",
    "\n",
    "samples=[elem for elem in X_val] \n",
    "val=FrameLevelDataset(samples,y_val)\n",
    "\n",
    "samples=[elem for elem in X_test_set] \n",
    "test=FrameLevelDataset(samples,y_test_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SZ=16\n",
    "\n",
    "train_batches = DataLoader(train,batch_size=BATCH_SZ,shuffle=True,num_workers=4)\n",
    "val_batches = DataLoader(val,batch_size=BATCH_SZ,shuffle=True,num_workers=4)\n",
    "test_batches = DataLoader(test,batch_size=BATCH_SZ,shuffle=True,num_workers=4)\n",
    "\n",
    "INPUT_SZ=6\n",
    "NUM_CLASSES=10\n",
    "NUM_LAYERS=1\n",
    "HIDDEN_SIZE=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "model=BasicLSTM(INPUT_SZ,HIDDEN_SIZE,NUM_CLASSES,NUM_LAYERS,bidirectional=True)\n",
    "EPOCHS=35\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):  \n",
    "    scheduler.step()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    for index,instance in enumerate(train_batches):\n",
    "\n",
    "        features,labels,lengths_b=instance     \n",
    "        features = features.type(torch.FloatTensor)\n",
    "     \n",
    "        orders=np.argsort(-lengths_b)\n",
    "        sorted_lengths = lengths_b[orders]\n",
    "        sorted_labels = labels[orders]\n",
    "        sorted_feats = features[orders]\n",
    "        model.zero_grad()\n",
    "        \n",
    "\n",
    "        prediction_vec = model(sorted_feats,sorted_lengths)\n",
    "        loss = loss_function(prediction_vec,labels)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
