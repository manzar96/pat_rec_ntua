{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c26d26b35b1b76e060f6e7a57a64d31f13cb323"
   },
   "source": [
    "**Βήμα 11β: Multitask Learning**\n",
    "Η βασική ιδέα του multitask learning είναι η δημιουργία ενός μοντέλου το οποίο θα κάνει προβλέψεις ή ταξινόμηση(classification) όχι μόνο σε 1 task αλλά σε περισσότερα. Παρακάτω υλοιποιήσαμε ένα hard parameter sharing μοντέλο. Με βάση αυτό, τα πρώτα layers (shared layers) του νευρωνικού μαθαίνουν την γενική πληροφορία και έχουν κοινά βάρη για όλα τα tasks. Tα επόμενα layers είναι ξεχωριστά για κάθε task με αποτέλεσμα κάθε μέρος του νευρωνικού να \"μαθαίνει\" πληροφορία για την ικανοποίηση συγκεκριμένου task.Αυτό γίνεται με χρήση διαφορετικών βαρών (τα layers δεν ειναι shared).\n",
    "\n",
    "Παρατηρούμε ότι το μοντέλο δίνει καλύτερα αποτελέσματα από αυτά του βήματος 10( καθώς είναι πιο generalized).\n",
    "\n",
    "(Κάνουμε χρήση του cnn γενικού μοντέλου)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "class_mapping = {\n",
    "    'Rock': 'Rock',\n",
    "    'Psych-Rock': 'Rock',\n",
    "    'Indie-Rock': None,\n",
    "    'Post-Rock': 'Rock',\n",
    "    'Psych-Folk': 'Folk',\n",
    "    'Folk': 'Folk',\n",
    "    'Metal': 'Metal',\n",
    "    'Punk': 'Metal',\n",
    "    'Post-Punk': None,\n",
    "    'Trip-Hop': 'Trip-Hop',\n",
    "    'Pop': 'Pop',\n",
    "    'Electronic': 'Electronic',\n",
    "    'Hip-Hop': 'Hip-Hop',\n",
    "    'Classical': 'Classical',\n",
    "    'Blues': 'Blues',\n",
    "    'Chiptune': 'Electronic',\n",
    "    'Jazz': 'Jazz',\n",
    "    'Soundtrack': None,\n",
    "    'International': None,\n",
    "    'Old-Time': None\n",
    "}\n",
    "\n",
    "\n",
    "def torch_train_val_split(\n",
    "        dataset, batch_train, batch_eval,\n",
    "        val_size=.2, shuffle=True, seed=42):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    val_split = int(np.floor(val_size * dataset_size))\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices = indices[val_split:]\n",
    "    val_indices = indices[:val_split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset,\n",
    "                              batch_size=batch_train,\n",
    "                              sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset,\n",
    "                            batch_size=batch_eval,\n",
    "                            sampler=val_sampler)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def read_spectrogram(spectrogram_file, chroma=True):\n",
    "    with gzip.GzipFile(spectrogram_file, 'r') as f:\n",
    "        spectrograms = np.load(f)\n",
    "    # spectrograms contains a fused mel spectrogram and chromagram\n",
    "    # Decompose as follows\n",
    "    return spectrograms.T\n",
    "\n",
    "\n",
    "class LabelTransformer(LabelEncoder):\n",
    "    def inverse(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).inverse_transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).inverse_transform([y])\n",
    "\n",
    "    def transform(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).transform([y])\n",
    "\n",
    "        \n",
    "class PaddingTransform(object):\n",
    "    def __init__(self, max_length, padding_value=0):\n",
    "        self.max_length = max_length\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "    def __call__(self, s):\n",
    "        if len(s) == self.max_length:\n",
    "            return s\n",
    "\n",
    "        if len(s) > self.max_length:\n",
    "            return s[:self.max_length]\n",
    "\n",
    "        if len(s) < self.max_length:\n",
    "            s1 = copy.deepcopy(s)\n",
    "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
    "            s1 = np.vstack((s1, pad))\n",
    "            return s1\n",
    "\n",
    "        \n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, path, class_mapping=None, train=True, max_length=-1):\n",
    "        t = 'train' if train else 'test'\n",
    "        p = os.path.join(path, t)\n",
    "        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
    "        self.files, labels = self.get_files_labels(self.index, class_mapping)\n",
    "        #print(self.files)\n",
    "        \n",
    "        self.feats = [read_spectrogram(os.path.join(p, f+\".fused.full.npy.gz\")) for f in self.files]\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "        #self.label_transformer = LabelTransformer()\n",
    "        #if isinstance(labels, (list, tuple)):\n",
    "            #self.labels = np.array(self.label_transformer.fit_transform(labels)).astype('int64')\n",
    "        self.labels=labels\n",
    "    def get_files_labels(self, txt, class_mapping):\n",
    "        with open(txt, 'r') as fd:\n",
    "            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n",
    "            \n",
    "        files, labels = [], []\n",
    "        for l in lines:\n",
    "            l=l[0].split(\",\")\n",
    "            b=l[1:]\n",
    "            b = list(map(float,b))\n",
    "            files.append(l[0])\n",
    "            \n",
    "            labels.append(b)\n",
    "        return files, labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        l = min(self.lengths[item], self.max_length)\n",
    "        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d2700c41a228e9d32c1111f4abfde277b2cdd39c"
   },
   "outputs": [],
   "source": [
    "BATCH_SZ=32\n",
    "\n",
    "specs = SpectrogramDataset('../input/data/data/multitask_dataset/', train=True, class_mapping=class_mapping, max_length=-1)\n",
    "train_loader, val_loader = torch_train_val_split(specs, BATCH_SZ ,BATCH_SZ, val_size=.33)\n",
    "#test_loader = DataLoader(SpectrogramDataset('../input/data/data/multitask_dataset/', train=False, class_mapping=class_mapping, max_length=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "e68bd4a462a64eb9e83946138c7df915adb06492"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy import stats\n",
    "\n",
    "class ConvNetMulty(nn.Module):\n",
    "    def __init__(self,input_channels,out_channels,kernel_sz,stride,padding, num_classes):\n",
    "        super(ConvNetMulty, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 4, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(16 , 32 , kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        )\n",
    "        \n",
    "        self.dense1_task1= nn.Linear(6720,500) \n",
    "        self.dense2_task1 = nn.Linear(500,1)\n",
    "        \n",
    "        self.dense1_task2= nn.Linear(6720,500) \n",
    "        self.dense2_task2 = nn.Linear(500,1)\n",
    "        \n",
    "        self.dense1_task3= nn.Linear(6720,500) \n",
    "        self.dense2_task3 = nn.Linear(500,1)\n",
    "\n",
    "        \n",
    "    def forward(self, x,lengths):\n",
    "        #print(x.shape)\n",
    "        x = x.transpose(1, 2)\n",
    "        #print(x.shape)\n",
    "        x.unsqueeze_(1)\n",
    "        #print(x.shape)\n",
    "        out1 = self.layer1(x)\n",
    "        #print(out1.shape)\n",
    "        out2= self.layer2(out1)\n",
    "        #print(out2.shape)\n",
    "        out3= self.layer3(out2)\n",
    "        #print(out3.shape)\n",
    "        out4= self.layer4(out3)\n",
    "        #print(out4.shape)\n",
    "        \n",
    "    \n",
    "        out_flat=out4.reshape(-1,out4.size(1)*out4.size(2)*out4.size(3))\n",
    "        #print(out_flat.shape)\n",
    "        \n",
    "        \n",
    "        #implementing fully connected layers\n",
    "        \n",
    "        hidden_out_task1 = self.dense1_task1(out_flat)\n",
    "        final_out_task1 = self.dense2_task1(hidden_out_task1)\n",
    "        \n",
    "        hidden_out_task2 = self.dense1_task2(out_flat)\n",
    "        final_out_task2 = self.dense2_task2(hidden_out_task2)\n",
    "        \n",
    "        hidden_out_task3 = self.dense1_task3(out_flat)\n",
    "        final_out_task3 = self.dense2_task3(hidden_out_task3)\n",
    "        \n",
    "        return final_out_task1,final_out_task2,final_out_task3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c790cade6b47346d6d2ce6d7a4b63bd341e3d9df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetMulty(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense1_task1): Linear(in_features=6720, out_features=500, bias=True)\n",
       "  (dense2_task1): Linear(in_features=500, out_features=1, bias=True)\n",
       "  (dense1_task2): Linear(in_features=6720, out_features=500, bias=True)\n",
       "  (dense2_task2): Linear(in_features=500, out_features=1, bias=True)\n",
       "  (dense1_task3): Linear(in_features=6720, out_features=500, bias=True)\n",
       "  (dense2_task3): Linear(in_features=500, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs=35\n",
    "kernel_sz=3\n",
    "input_channels=1\n",
    "out_channels=1\n",
    "stride=2\n",
    "padding=2\n",
    "num_classes=1\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda\")\n",
    "\n",
    "model_cnn_regr_multy = ConvNetMulty(input_channels,out_channels,kernel_sz,stride,padding ,num_classes)\n",
    "model_cnn_regr_multy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "aa82edfc6111ced3acfe09b8ce0bd3eae2b43903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t \t Training Loss 170.61995668212572\n",
      "Epoch: 1 \t \t Training Loss 6.045845838884513\n",
      "Epoch: 2 \t \t Training Loss 0.8538095913827419\n",
      "Epoch: 3 \t \t Training Loss 0.3342576064169407\n",
      "Epoch: 4 \t \t Training Loss 0.24563510157167912\n",
      "Epoch: 5 \t \t Training Loss 0.18352844038357338\n",
      "Epoch: 6 \t \t Training Loss 0.16031182277947664\n",
      "Epoch: 7 \t \t Training Loss 0.13519544806331396\n",
      "Epoch: 8 \t \t Training Loss 0.11067655760173996\n",
      "Epoch: 9 \t \t Training Loss 0.10365207555393378\n",
      "Epoch: 10 \t \t Training Loss 0.09550154798974593\n",
      "Epoch: 11 \t \t Training Loss 0.07686404635508855\n",
      "Epoch: 12 \t \t Training Loss 0.08295637446766098\n",
      "Epoch: 13 \t \t Training Loss 0.07319866819307208\n",
      "Epoch: 14 \t \t Training Loss 0.07015231158584356\n",
      "Epoch: 15 \t \t Training Loss 0.06546815655504663\n",
      "Epoch: 16 \t \t Training Loss 0.06411261825511853\n",
      "Epoch: 17 \t \t Training Loss 0.05718735636522373\n",
      "Epoch: 18 \t \t Training Loss 0.05736007681116462\n",
      "Epoch: 19 \t \t Training Loss 0.05941177966694037\n",
      "Epoch: 20 \t \t Training Loss 0.049719756158689656\n",
      "Epoch: 21 \t \t Training Loss 0.0480999726181229\n",
      "Epoch: 22 \t \t Training Loss 0.048711277854939304\n",
      "Epoch: 23 \t \t Training Loss 0.04960320804578563\n",
      "Epoch: 24 \t \t Training Loss 0.042958986635009445\n",
      "Epoch: 25 \t \t Training Loss 0.045752161337683596\n",
      "Epoch: 26 \t \t Training Loss 0.04130306552785138\n",
      "Epoch: 27 \t \t Training Loss 0.03954243481469651\n",
      "Epoch: 28 \t \t Training Loss 0.037998004738862314\n",
      "Epoch: 29 \t \t Training Loss 0.03634396412720283\n",
      "Epoch: 30 \t \t Training Loss 0.03367585805244744\n",
      "Epoch: 31 \t \t Training Loss 0.038924751337617636\n",
      "Epoch: 32 \t \t Training Loss 0.035324481781572104\n",
      "Epoch: 33 \t \t Training Loss 0.028970209881663322\n",
      "Epoch: 34 \t \t Training Loss 0.03169339600329598\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_regr_multy.parameters())\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "    #always necessary. So we comment the following line.\n",
    "    #with torch.autograd(): \n",
    "    model_cnn_regr_multy.train()\n",
    "    #scheduler.step()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    #train model in each epoch\n",
    "    for index,instance in enumerate(train_loader):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        #features,labels,lengths=instance\n",
    "        \n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction_vec_task1,prediction_vec_task2,prediction_vec_task3 = model_cnn_regr_multy(features,lengths)\n",
    "        prediction_vec_task1.to(device)\n",
    "        prediction_vec_task2.to(device)\n",
    "        prediction_vec_task3.to(device)\n",
    "        \n",
    "        \n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        valence_labels = valence_labels.unsqueeze(1)\n",
    "        energy_labels = energy_labels.unsqueeze(1)\n",
    "        dance_labels = dance_labels.unsqueeze(1)\n",
    "        \n",
    "        loss1 = criterion(prediction_vec_task1,valence_labels)\n",
    "        loss2 = criterion(prediction_vec_task2,energy_labels)\n",
    "        loss3 = criterion(prediction_vec_task3,dance_labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss=loss1*0.2+loss2*0.6+loss3*0.2\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "5d2c50aebd0dce7d572a81ce7028e8d3d0dae779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearnman's correlation for CNN-2d in validation set (predicting all):  0.33914164870424757 0.5645039200525802 0.5470677740221713\n",
      "Mean Spearnman's correlation for CNN-2d in validation set (predicting all):  0.48357111425966637\n"
     ]
    }
   ],
   "source": [
    "model_cnn_regr_multy.eval()\n",
    "\n",
    "n_samples = 0\n",
    "SE = 0\n",
    "spearman1=[]\n",
    "spearman2=[]\n",
    "spearman3=[]\n",
    "running_average_loss=0\n",
    "with torch.no_grad():\n",
    "    for index, instance in enumerate(val_loader):\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        \n",
    "    \n",
    "        out1,out2,out3 = model_cnn_regr_multy(features,lengths)\n",
    "        out1.to(device)\n",
    "        out2.to(device)\n",
    "        out3.to(device)\n",
    "        #print(out)\n",
    "        #print(valence_labels)\n",
    "        valence_labels = valence_labels.unsqueeze(1)\n",
    "        energy_labels = energy_labels.unsqueeze(1)\n",
    "        dance_labels = dance_labels.unsqueeze(1)\n",
    "        \n",
    "    \n",
    "        spearman1.append(stats.spearmanr(valence_labels.cpu().squeeze(),out1.cpu().squeeze(),axis=0)[0])\n",
    "        spearman2.append(stats.spearmanr(energy_labels.cpu().squeeze(),out2.cpu().squeeze(),axis=0)[0])\n",
    "        spearman3.append(stats.spearmanr(dance_labels.cpu().squeeze(),out3.cpu().squeeze(),axis=0)[0])\n",
    "        \n",
    "a,b,c=np.mean(spearman1),np.mean(spearman2),np.mean(spearman3)\n",
    "print(\"Spearnman's correlation for CNN-2d in validation set (predicting all): \" , np.mean(spearman1),np.mean(spearman2),np.mean(spearman3)  )\n",
    "print(\"Mean Spearnman's correlation for CNN-2d in validation set (predicting all): \" , (a+b+c)/3  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
