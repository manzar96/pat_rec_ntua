{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bfa5334d75ac4497808d5ff0a442b91a3fb101e1"
   },
   "source": [
    "**Βήμα10:**\n",
    "Παρακάτω έχουμε υλοποιήσει τα μοντέλα που ζητήθηκαν για το βημα 10 (3 για κάθε κατηγορία - valence,energy,danceability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "class_mapping = {\n",
    "    'Rock': 'Rock',\n",
    "    'Psych-Rock': 'Rock',\n",
    "    'Indie-Rock': None,\n",
    "    'Post-Rock': 'Rock',\n",
    "    'Psych-Folk': 'Folk',\n",
    "    'Folk': 'Folk',\n",
    "    'Metal': 'Metal',\n",
    "    'Punk': 'Metal',\n",
    "    'Post-Punk': None,\n",
    "    'Trip-Hop': 'Trip-Hop',\n",
    "    'Pop': 'Pop',\n",
    "    'Electronic': 'Electronic',\n",
    "    'Hip-Hop': 'Hip-Hop',\n",
    "    'Classical': 'Classical',\n",
    "    'Blues': 'Blues',\n",
    "    'Chiptune': 'Electronic',\n",
    "    'Jazz': 'Jazz',\n",
    "    'Soundtrack': None,\n",
    "    'International': None,\n",
    "    'Old-Time': None\n",
    "}\n",
    "\n",
    "\n",
    "def torch_train_val_split(\n",
    "        dataset, batch_train, batch_eval,\n",
    "        val_size=.2, shuffle=True, seed=42):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    val_split = int(np.floor(val_size * dataset_size))\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices = indices[val_split:]\n",
    "    val_indices = indices[:val_split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset,\n",
    "                              batch_size=batch_train,\n",
    "                              sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset,\n",
    "                            batch_size=batch_eval,\n",
    "                            sampler=val_sampler)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def read_spectrogram(spectrogram_file, chroma=True):\n",
    "    with gzip.GzipFile(spectrogram_file, 'r') as f:\n",
    "        spectrograms = np.load(f)\n",
    "    # spectrograms contains a fused mel spectrogram and chromagram\n",
    "    # Decompose as follows\n",
    "    return spectrograms.T\n",
    "\n",
    "\n",
    "class LabelTransformer(LabelEncoder):\n",
    "    def inverse(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).inverse_transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).inverse_transform([y])\n",
    "\n",
    "    def transform(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).transform([y])\n",
    "\n",
    "        \n",
    "class PaddingTransform(object):\n",
    "    def __init__(self, max_length, padding_value=0):\n",
    "        self.max_length = max_length\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "    def __call__(self, s):\n",
    "        if len(s) == self.max_length:\n",
    "            return s\n",
    "\n",
    "        if len(s) > self.max_length:\n",
    "            return s[:self.max_length]\n",
    "\n",
    "        if len(s) < self.max_length:\n",
    "            s1 = copy.deepcopy(s)\n",
    "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
    "            s1 = np.vstack((s1, pad))\n",
    "            return s1\n",
    "\n",
    "        \n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, path, class_mapping=None, train=True, max_length=-1):\n",
    "        t = 'train' if train else 'test'\n",
    "        p = os.path.join(path, t)\n",
    "        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
    "        self.files, labels = self.get_files_labels(self.index, class_mapping)\n",
    "        #print(self.files)\n",
    "        \n",
    "        self.feats = [read_spectrogram(os.path.join(p, f+\".fused.full.npy.gz\")) for f in self.files]\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "        #self.label_transformer = LabelTransformer()\n",
    "        #if isinstance(labels, (list, tuple)):\n",
    "            #self.labels = np.array(self.label_transformer.fit_transform(labels)).astype('int64')\n",
    "        self.labels=labels\n",
    "    def get_files_labels(self, txt, class_mapping):\n",
    "        with open(txt, 'r') as fd:\n",
    "            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n",
    "            \n",
    "        files, labels = [], []\n",
    "        for l in lines:\n",
    "            l=l[0].split(\",\")\n",
    "            b=l[1:]\n",
    "            b = list(map(float,b))\n",
    "            files.append(l[0])\n",
    "            \n",
    "            labels.append(b)\n",
    "        return files, labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        l = min(self.lengths[item], self.max_length)\n",
    "        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d41fa2bca26c8c21ee72a4cb0705a369903f4784"
   },
   "outputs": [],
   "source": [
    "BATCH_SZ=32\n",
    "\n",
    "specs = SpectrogramDataset('../input/data/data/multitask_dataset/', train=True, class_mapping=class_mapping, max_length=-1)\n",
    "train_loader, val_loader = torch_train_val_split(specs, BATCH_SZ ,BATCH_SZ, val_size=.33)\n",
    "#test_loader = DataLoader(SpectrogramDataset('../input/data/data/multitask_dataset/', train=False, class_mapping=class_mapping, max_length=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3fee0ca9a98e7102182c6e9d6d1ed0ae6ac2ceb7"
   },
   "source": [
    "**REGRESSION FOR VALENCE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "769ed9e2db6e0e7ec78f572dca088647d6265504"
   },
   "source": [
    "1. LSTM for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "756b59bcd0266f03ceeb5362c11ee2848ad10bf6"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy import stats\n",
    "\n",
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, input_dim,rnn_size, output_dim, num_layers,dropout_type=None,dropout=0, bidirectional=False):\n",
    "        super(BasicLSTM, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size\n",
    "        self.dropout=dropout\n",
    "        '''\n",
    "        if dropout_type is not None:\n",
    "            if dropout_type = 'Variational_Locked_Dropout'\n",
    "            self.dropout = Variational_LockedDropout(dropout=dropout_prob)\n",
    "        '''\n",
    "            \n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        # Initialize the LSTM, Dropout, Output layers\n",
    "        \n",
    "        \n",
    "        #for non-bidirectional:\n",
    "        #we assume that rnn-size is the number of lstm-units...\n",
    "        #input_dim is the vector that each unit will receive as input..\n",
    "        #hidden_dim at basic lstm is the same as hidden_dim...\n",
    "        #so we have...\n",
    "        self.num_layers=num_layers\n",
    "        self.hidden_dim = rnn_size # OR self.hidden_dim = self.feature_size\n",
    "        if self.bidirectional:\n",
    "            self.lstm = nn.LSTM(input_dim,self.hidden_dim//2,num_layers=num_layers,bidirectional=bidirectional,\n",
    "                                dropout=self.dropout,batch_first=True)\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(input_dim,self.hidden_dim,num_layers=num_layers,bidirectional=bidirectional,\n",
    "                                dropout=self.dropout,batch_first=True)\n",
    "\n",
    "        #using batch_first=True affects only the input!\n",
    "        # if the input is at form seq_len,batch,features batch_first=True is not needed\n",
    "        \n",
    "        #self.hidden = self.init_hidden() #initialize hidden state(and cell state)\n",
    "       \n",
    "        self.output_set_size = output_dim\n",
    "        self.hidden2output = nn.Linear(self.hidden_dim,self.output_set_size)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\" \n",
    "            x : 3D numpy array of dimension N x L x D\n",
    "                N: batch index\n",
    "                L: sequence index\n",
    "                D: feature index\n",
    "\n",
    "            lengths: N x 1\n",
    "         \"\"\"\n",
    "        \n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        \n",
    "        # You must have all of the outputs of the LSTM, but you need only the last one (that does not exceed the sequence length)\n",
    "        # To get it use the last_timestep method\n",
    "        # Then pass it through the remaining network \n",
    "        lstm_out,_ = self.lstm(x)\n",
    "        last_lstm_out = self.last_timestep(lstm_out,lengths)   \n",
    "        out_space = self.hidden2output(last_lstm_out)\n",
    "        return out_space\n",
    "\n",
    "    def last_timestep(self, outputs, lengths, bidirectional=False):\n",
    "        \"\"\"\n",
    "            Returns the last output of the LSTM taking into account the zero padding\n",
    "        \"\"\"\n",
    "        if self.bidirectional:\n",
    "            forward, backward = self.split_directions(outputs)\n",
    "            last_forward = self.last_by_index(forward, lengths)\n",
    "            last_backward = backward[:, 0, :]\n",
    "            # Concatenate and return - maybe add more functionalities like average\n",
    "            return torch.cat((last_forward, last_backward), dim=-1)\n",
    "\n",
    "        else:\n",
    "            return self.last_by_index(outputs, lengths)\n",
    "\n",
    "    @staticmethod\n",
    "    def split_directions(outputs):\n",
    "        direction_size = int(outputs.size(-1) / 2)\n",
    "        forward = outputs[:, :, :direction_size]\n",
    "        backward = outputs[:, :, direction_size:]\n",
    "        return forward, backward\n",
    "\n",
    "    @staticmethod\n",
    "    def last_by_index(outputs, lengths):\n",
    "        # Index of the last output for each sequence.\n",
    "        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),\n",
    "                                               outputs.size(2)).unsqueeze(1)\n",
    "        return outputs.gather(1, idx).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "51e394790c571013e6738c129e32fc27b491b071"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicLSTM(\n",
       "  (lstm): LSTM(140, 20, batch_first=True)\n",
       "  (hidden2output): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SZ=140\n",
    "NUM_CLASSES=1\n",
    "NUM_LAYERS=1\n",
    "HIDDEN_SIZE=20\n",
    "DROPOUT=0\n",
    "\n",
    "num_epochs=30\n",
    "\n",
    "device=torch.device(\"cuda\")\n",
    "model_lstm_regr_val = BasicLSTM(INPUT_SZ,HIDDEN_SIZE,NUM_CLASSES,NUM_LAYERS,dropout=DROPOUT,bidirectional=False)\n",
    "model_lstm_regr_val.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a821f1344a70c5c56e73a399973a193c6ef3cce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t \t Training Loss 0.11498838135351737\n",
      "Epoch: 1 \t \t Training Loss 0.06630488360921542\n",
      "Epoch: 2 \t \t Training Loss 0.06607402053972085\n",
      "Epoch: 3 \t \t Training Loss 0.0662877291130523\n",
      "Epoch: 4 \t \t Training Loss 0.06607344700023532\n",
      "Epoch: 5 \t \t Training Loss 0.06522830746447046\n",
      "Epoch: 6 \t \t Training Loss 0.06520008482038975\n",
      "Epoch: 7 \t \t Training Loss 0.06505523901432753\n",
      "Epoch: 8 \t \t Training Loss 0.06558357582738002\n",
      "Epoch: 9 \t \t Training Loss 0.06457203424846132\n",
      "Epoch: 10 \t \t Training Loss 0.06498052769651015\n",
      "Epoch: 11 \t \t Training Loss 0.06466090430816014\n",
      "Epoch: 12 \t \t Training Loss 0.06573344627395272\n",
      "Epoch: 13 \t \t Training Loss 0.06454511002327006\n",
      "Epoch: 14 \t \t Training Loss 0.06466388997311394\n",
      "Epoch: 15 \t \t Training Loss 0.06485450034961104\n",
      "Epoch: 16 \t \t Training Loss 0.0647758796500663\n",
      "Epoch: 17 \t \t Training Loss 0.06430634157732129\n",
      "Epoch: 18 \t \t Training Loss 0.0652501150034368\n",
      "Epoch: 19 \t \t Training Loss 0.06432852086921532\n",
      "Epoch: 20 \t \t Training Loss 0.06531793298199773\n",
      "Epoch: 21 \t \t Training Loss 0.06435645713160436\n",
      "Epoch: 22 \t \t Training Loss 0.0642743466111521\n",
      "Epoch: 23 \t \t Training Loss 0.06551184318959713\n",
      "Epoch: 24 \t \t Training Loss 0.06422210019081831\n",
      "Epoch: 25 \t \t Training Loss 0.06477533249805371\n",
      "Epoch: 26 \t \t Training Loss 0.06493734397614996\n",
      "Epoch: 27 \t \t Training Loss 0.06437615941589077\n",
      "Epoch: 28 \t \t Training Loss 0.06362591916695237\n",
      "Epoch: 29 \t \t Training Loss 0.06432470337798198\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_lstm_regr_val.parameters(),lr=0.01)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "    #always necessary. So we comment the following line.\n",
    "    #with torch.autograd(): \n",
    "    model_lstm_regr_val.train()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    #train model in each epoch\n",
    "    for index,instance in enumerate(train_loader):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        #features,labels,lengths=instance\n",
    "        #print(instance)\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction_vec = model_lstm_regr_val(features,lengths)\n",
    "        prediction_vec.to(device)\n",
    "        #print(prediction_vec.shape)\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        valence_labels=valence_labels.unsqueeze(1)\n",
    "        loss = criterion(prediction_vec,valence_labels)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "31d68b67268115d56fa7b46329b65151cb7e6e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearnman's correlation for LSTM in validation set (predicting valence):  0.03340419179081181\n"
     ]
    }
   ],
   "source": [
    "model_lstm_regr_val.eval()\n",
    "\n",
    "n_samples = 0\n",
    "SE = 0\n",
    "spearman=[]\n",
    "running_average_loss=0\n",
    "with torch.no_grad():\n",
    "    for index, instance in enumerate(val_loader):\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        out = model_lstm_regr_val(features,lengths)\n",
    "        out = out.to(device)\n",
    "        #print(out)\n",
    "        #print(valence_labels)\n",
    "\n",
    "        valence_labels = valence_labels.unsqueeze(1)\n",
    "        E = valence_labels-out\n",
    "        SE = pow(E,2).sum().item() + SE\n",
    "        #print(SE)\n",
    "        n_samples+=features.shape[0]\n",
    "        \n",
    "        spearman.append(stats.spearmanr(valence_labels.cpu().squeeze(),out.cpu().squeeze(),axis=0)[0])\n",
    "\n",
    "print(\"Spearnman's correlation for LSTM in validation set (predicting valence): \" , np.mean(spearman) )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6585b2cb3f767c97ac5a4a4c4b5ea3ece0df99ab"
   },
   "source": [
    "2. CNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "e56b1a650a4a7260bbe9a022d9f07e8cb567c07a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,input_channels,out_channels,kernel_sz,stride,padding, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 4, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(16 , 32 , kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        )\n",
    "        \n",
    "        self.dense1= nn.Linear(6720,500) \n",
    "        self.dense2 = nn.Linear(500,1)\n",
    "\n",
    "        \n",
    "    def forward(self, x,lengths):\n",
    "        #print(x.shape)\n",
    "        x = x.transpose(1, 2)\n",
    "        #print(x.shape)\n",
    "        x.unsqueeze_(1)\n",
    "        #print(x.shape)\n",
    "        out1 = self.layer1(x)\n",
    "        #print(out1.shape)\n",
    "        out2= self.layer2(out1)\n",
    "        #print(out2.shape)\n",
    "        out3= self.layer3(out2)\n",
    "        #print(out3.shape)\n",
    "        out4= self.layer4(out3)\n",
    "        #print(out4.shape)\n",
    "        \n",
    "    \n",
    "        out_flat=out4.reshape(-1,out4.size(1)*out4.size(2)*out4.size(3))\n",
    "        #print(out_flat.shape)\n",
    "        \n",
    "        \n",
    "        #implementing fully connected layers\n",
    "        \n",
    "        hidden_out = self.dense1(out_flat)\n",
    "        final_out = self.dense2(hidden_out)\n",
    "        \n",
    "        return final_out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d1abfefddd24ca503636e41ff804fb29395ec37c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense1): Linear(in_features=6720, out_features=500, bias=True)\n",
       "  (dense2): Linear(in_features=500, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs=35\n",
    "kernel_sz=3\n",
    "input_channels=1\n",
    "out_channels=1\n",
    "stride=2\n",
    "padding=2\n",
    "num_classes=1\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda\")\n",
    "\n",
    "model_cnn_regr_val = ConvNet(input_channels,out_channels,kernel_sz,stride,padding ,num_classes)\n",
    "model_cnn_regr_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "2f03e156bb7f53056db6dd6c71bb7e93298427a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t \t Training Loss 207.47290225327015\n",
      "Epoch: 1 \t \t Training Loss 6.196245099107425\n",
      "Epoch: 2 \t \t Training Loss 0.5826382904003063\n",
      "Epoch: 3 \t \t Training Loss 0.2720083637783925\n",
      "Epoch: 4 \t \t Training Loss 0.1813507480546832\n",
      "Epoch: 5 \t \t Training Loss 0.14904492069035769\n",
      "Epoch: 6 \t \t Training Loss 0.12134294801702102\n",
      "Epoch: 7 \t \t Training Loss 0.11062451762457688\n",
      "Epoch: 8 \t \t Training Loss 0.09226172138005495\n",
      "Epoch: 9 \t \t Training Loss 0.08942352638890345\n",
      "Epoch: 10 \t \t Training Loss 0.08068473202486832\n",
      "Epoch: 11 \t \t Training Loss 0.07322605854521196\n",
      "Epoch: 12 \t \t Training Loss 0.06569720525294542\n",
      "Epoch: 13 \t \t Training Loss 0.06696520745754242\n",
      "Epoch: 14 \t \t Training Loss 0.061552266124635935\n",
      "Epoch: 15 \t \t Training Loss 0.05379380751401186\n",
      "Epoch: 16 \t \t Training Loss 0.0564881592678527\n",
      "Epoch: 17 \t \t Training Loss 0.05349653773009777\n",
      "Epoch: 18 \t \t Training Loss 0.051218101754784584\n",
      "Epoch: 19 \t \t Training Loss 0.04545040133719643\n",
      "Epoch: 20 \t \t Training Loss 0.05046098151554664\n",
      "Epoch: 21 \t \t Training Loss 0.04185096803121269\n",
      "Epoch: 22 \t \t Training Loss 0.04059656492124001\n",
      "Epoch: 23 \t \t Training Loss 0.04167237761430442\n",
      "Epoch: 24 \t \t Training Loss 0.038354427476103105\n",
      "Epoch: 25 \t \t Training Loss 0.03685590586004158\n",
      "Epoch: 26 \t \t Training Loss 0.03588549792766571\n",
      "Epoch: 27 \t \t Training Loss 0.03662609510744611\n",
      "Epoch: 28 \t \t Training Loss 0.032908763426045574\n",
      "Epoch: 29 \t \t Training Loss 0.03240209026262164\n",
      "Epoch: 30 \t \t Training Loss 0.03941395583872994\n",
      "Epoch: 31 \t \t Training Loss 0.03333051595836878\n",
      "Epoch: 32 \t \t Training Loss 0.032379149847353496\n",
      "Epoch: 33 \t \t Training Loss 0.03537624329328537\n",
      "Epoch: 34 \t \t Training Loss 0.029801189433783293\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_regr_val.parameters())\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "    #always necessary. So we comment the following line.\n",
    "    #with torch.autograd(): \n",
    "    model_cnn_regr_val.train()\n",
    "    #scheduler.step()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    #train model in each epoch\n",
    "    for index,instance in enumerate(train_loader):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        #features,labels,lengths=instance\n",
    "        \n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction_vec = model_cnn_regr_val(features,lengths)\n",
    "        prediction_vec.to(device)\n",
    "        \n",
    "        \n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        valence_labels = valence_labels.unsqueeze(1)\n",
    "        \n",
    "        loss = criterion(prediction_vec,valence_labels)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "32339d286fbcedc7edd6dba96a18443ddaf8980f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearnman's correlation for CNN-2D in validation set (predicting valence):  0.4285448002238674\n"
     ]
    }
   ],
   "source": [
    "model_cnn_regr_val.eval()\n",
    "\n",
    "n_samples = 0\n",
    "SE = 0\n",
    "spearman=[]\n",
    "with torch.no_grad():\n",
    "    for index, instance in enumerate(val_loader):\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        \n",
    "    \n",
    "        out = model_cnn_regr_val(features,lengths)\n",
    "        out = out.to(device)\n",
    "        \n",
    "        valence_labels = valence_labels.unsqueeze(1)\n",
    "        E = valence_labels-out\n",
    "        SE = pow(E,2).sum().item() + SE\n",
    "        #print(SE)\n",
    "        n_samples+=features.shape[0]\n",
    "        \n",
    "        \n",
    "        spearman.append(stats.spearmanr(valence_labels.cpu().squeeze(),out.cpu().squeeze(),axis=0)[0])\n",
    "\n",
    "print(\"Spearnman's correlation for CNN-2D in validation set (predicting valence): \" , np.mean(spearman) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1ff8fcc069b15a99b4aa410be93ac30c494df4d3"
   },
   "source": [
    "3. CNN-LSTM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "5b5d632cf33cb8b7085e4b006b11f923b658f317"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self,input_channels,out_channels,kernel_sz,stride,padding, num_classes,input_dim,rnn_size, output_dim, num_layers,dropout_type=None,dropout=0, bidirectional=False):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 256, kernel_size=kernel_sz, stride=stride, padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=kernel_sz, stride=stride, padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.bidirectional = bidirectional\n",
    "        self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size\n",
    "        self.dropout=dropout\n",
    "        '''\n",
    "        if dropout_type is not None:\n",
    "            if dropout_type = 'Variational_Locked_Dropout'\n",
    "            self.dropout = Variational_LockedDropout(dropout=dropout_prob)\n",
    "        '''\n",
    "            \n",
    "        # --------------- Insert your code here ---------------- #\n",
    "        # Initialize the LSTM, Dropout, Output layers\n",
    "        \n",
    "        \n",
    "        #for non-bidirectional:\n",
    "        #we assume that rnn-size is the number of lstm-units...\n",
    "        #input_dim is the vector that each unit will receive as input..\n",
    "        #hidden_dim at basic lstm is the same as hidden_dim...\n",
    "        #so we have...\n",
    "        self.num_layers=num_layers\n",
    "        self.hidden_dim = rnn_size # OR self.hidden_dim = self.feature_size\n",
    "        if self.bidirectional:\n",
    "            self.lstm = nn.LSTM(input_dim,self.hidden_dim//2,num_layers=num_layers,bidirectional=bidirectional,\n",
    "                                dropout=self.dropout,batch_first=True)\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(input_dim,self.hidden_dim,num_layers=num_layers,bidirectional=bidirectional,\n",
    "                                dropout=self.dropout,batch_first=True)\n",
    "\n",
    "        #using batch_first=True affects only the input! \n",
    "        # if the input is at form seq_len,batch,features batch_first=True is not needed\n",
    "        \n",
    "        #self.hidden = self.init_hidden() #initialize hidden state(and cell state)\n",
    "        \n",
    "        #use a linear transformation from lstm hidden_state space to ouput space..\n",
    "        #for digit classification we want to classify a sequence to 0-9 digits. So we will use as output dim the number 10.\n",
    "        self.output_set_size = output_dim\n",
    "        self.hidden2output = nn.Linear(self.hidden_dim,self.output_set_size)\n",
    "        \n",
    "    def forward(self, x,lengths):\n",
    "  \n",
    "        #print(x.shape)\n",
    "        x = x.transpose(1, 2)\n",
    "        #print(x.shape)\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.transpose(1, 2)\n",
    "        #print(out.shape)\n",
    "        #newlengths = torch.ones(out.shape[0])\n",
    "        #newlengths=newlengths * (out.shape[1])\n",
    "        newlengths = lengths//4-1\n",
    "        #print(newlengths)\n",
    "        newlengths = newlengths.type(torch.LongTensor).to(device)\n",
    "        \n",
    "       \n",
    "        #print(out.shape)\n",
    "        lstm_out,_ = self.lstm(out)\n",
    "        #print(lstm_out.shape)\n",
    "        last_lstm_out = self.last_timestep(lstm_out,newlengths)   \n",
    "        out_space = self.hidden2output(last_lstm_out)\n",
    "        \n",
    "        #print(out_space.shape)\n",
    "        #out_space = self.hidden2output(lstm_out)\n",
    "        \n",
    "        return out_space\n",
    "        \n",
    "    def last_timestep(self, outputs, lengths):\n",
    "        \"\"\"\n",
    "            Returns the last output of the LSTM taking into account the zero padding\n",
    "        \"\"\"\n",
    "        if self.bidirectional:\n",
    "            forward, backward = self.split_directions(outputs)\n",
    "            last_forward = self.last_by_index(forward, lengths)\n",
    "            last_backward = backward[:, 0, :]\n",
    "            # Concatenate and return - maybe add more functionalities like average\n",
    "            return torch.cat((last_forward, last_backward), dim=-1)\n",
    "\n",
    "        else:\n",
    "            return self.last_by_index(outputs, lengths)\n",
    "\n",
    "    @staticmethod\n",
    "    def split_directions(outputs):\n",
    "        direction_size = int(outputs.size(-1) / 2)\n",
    "        forward = outputs[:, :, :direction_size]\n",
    "        backward = outputs[:, :, direction_size:]\n",
    "        return forward, backward\n",
    "\n",
    "    @staticmethod\n",
    "    def last_by_index(outputs, lengths):\n",
    "        # Index of the last output for each sequence.\n",
    "        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),\n",
    "                                               outputs.size(2)).unsqueeze(1)\n",
    "        return outputs.gather(1, idx).squeeze()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "9dd0175971fc4fcbf67c400907c7d7a41666c152"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTM(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv1d(140, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(512, 20, batch_first=True)\n",
       "  (hidden2output): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_epochs=35\n",
    "kernel_sz=3\n",
    "input_channels=140\n",
    "out_channels=140\n",
    "stride=1\n",
    "padding=1\n",
    "num_classes=1\n",
    "\n",
    "INPUT_SZ=512\n",
    "NUM_CLASSES=1\n",
    "NUM_LAYERS=1\n",
    "HIDDEN_SIZE=20\n",
    "DROPOUT=0\n",
    "\n",
    "device=torch.device(\"cuda\")\n",
    "model_cnn_lstm_regr_val = ConvLSTM(input_channels,out_channels,kernel_sz,stride,padding ,num_classes,INPUT_SZ,HIDDEN_SIZE,NUM_CLASSES,NUM_LAYERS,dropout=DROPOUT,bidirectional=False)\n",
    "model_cnn_lstm_regr_val.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "de76ccbc3e9220f673e09795a4876c3d0bdc3485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t \t Training Loss 0.10728492215275764\n",
      "Epoch: 1 \t \t Training Loss 0.05740721353019277\n",
      "Epoch: 2 \t \t Training Loss 0.05420155202349027\n",
      "Epoch: 3 \t \t Training Loss 0.04631794593296945\n",
      "Epoch: 4 \t \t Training Loss 0.04408431029878557\n",
      "Epoch: 5 \t \t Training Loss 0.04025212349370122\n",
      "Epoch: 6 \t \t Training Loss 0.038446930857996144\n",
      "Epoch: 7 \t \t Training Loss 0.03930413032261034\n",
      "Epoch: 8 \t \t Training Loss 0.031898723604778446\n",
      "Epoch: 9 \t \t Training Loss 0.032362023213257395\n",
      "Epoch: 10 \t \t Training Loss 0.030159047106280923\n",
      "Epoch: 11 \t \t Training Loss 0.028260926793639857\n",
      "Epoch: 12 \t \t Training Loss 0.023967814825785656\n",
      "Epoch: 13 \t \t Training Loss 0.02537781683107217\n",
      "Epoch: 14 \t \t Training Loss 0.026873003458604217\n",
      "Epoch: 15 \t \t Training Loss 0.026161444334623713\n",
      "Epoch: 16 \t \t Training Loss 0.023727596853859723\n",
      "Epoch: 17 \t \t Training Loss 0.023460507897349697\n",
      "Epoch: 18 \t \t Training Loss 0.021960023053300876\n",
      "Epoch: 19 \t \t Training Loss 0.021477526053786278\n",
      "Epoch: 20 \t \t Training Loss 0.023333263971532386\n",
      "Epoch: 21 \t \t Training Loss 0.018601087504066527\n",
      "Epoch: 22 \t \t Training Loss 0.018287179719967146\n",
      "Epoch: 23 \t \t Training Loss 0.019673968393666048\n",
      "Epoch: 24 \t \t Training Loss 0.016874157746012013\n",
      "Epoch: 25 \t \t Training Loss 0.014607055267939964\n",
      "Epoch: 26 \t \t Training Loss 0.016417837042051058\n",
      "Epoch: 27 \t \t Training Loss 0.01885566080454737\n",
      "Epoch: 28 \t \t Training Loss 0.01469704780417184\n",
      "Epoch: 29 \t \t Training Loss 0.01327048942524319\n",
      "Epoch: 30 \t \t Training Loss 0.012150470594254633\n",
      "Epoch: 31 \t \t Training Loss 0.010513386087647328\n",
      "Epoch: 32 \t \t Training Loss 0.00838179764105007\n",
      "Epoch: 33 \t \t Training Loss 0.00801308530693253\n",
      "Epoch: 34 \t \t Training Loss 0.007630649507821848\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_lstm_regr_val.parameters())\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "    #always necessary. So we comment the following line.\n",
    "    #with torch.autograd(): \n",
    "    model_cnn_lstm_regr_val.train()\n",
    "    #scheduler.step()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    #train model in each epoch\n",
    "    for index,instance in enumerate(train_loader):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        #features,labels,lengths=instance\n",
    "        \n",
    "        features = instance[:][0]\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction_vec = model_cnn_lstm_regr_val(features,lengths)\n",
    "        prediction_vec.to(device)\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        valence_labels = valence_labels.unsqueeze(1)\n",
    "        \n",
    "        loss = criterion(prediction_vec,valence_labels)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "775a582575c8f3945d17d9a93c320b3a230aaa5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearnman's correlation for CNN-LSTM in validation set (predicting valence):  0.24241181466361428\n"
     ]
    }
   ],
   "source": [
    "model_cnn_lstm_regr_val.eval()\n",
    "\n",
    "n_samples = 0\n",
    "SE = 0\n",
    "spearman=[]\n",
    "with torch.no_grad():\n",
    "    for index, instance in enumerate(val_loader):\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        \n",
    "    \n",
    "        out = model_cnn_lstm_regr_val(features,lengths)\n",
    "        out = out.to(device)\n",
    "        \n",
    "        valence_labels = valence_labels.unsqueeze(1)\n",
    "        E = valence_labels-out\n",
    "        SE = pow(E,2).sum().item() + SE\n",
    "        #print(SE)\n",
    "        n_samples+=features.shape[0]\n",
    "\n",
    "        spearman.append(stats.spearmanr(valence_labels.cpu().squeeze(),out.cpu().squeeze(),axis=0)[0])\n",
    "\n",
    "print(\"Spearnman's correlation for CNN-LSTM in validation set (predicting valence): \" , np.mean(spearman) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b195f65a93b0a42733bc6dce6d73dea93266cbcb"
   },
   "source": [
    "**REGRESSION FOR ENERGY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cd184993a3c150c84936594a846513fd2906ec99"
   },
   "source": [
    "1. LSTM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "69b37dd279e41641e4b0eb0facee0f7fa65386f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicLSTM(\n",
       "  (lstm): LSTM(140, 40, batch_first=True)\n",
       "  (hidden2output): Linear(in_features=40, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SZ=140\n",
    "NUM_CLASSES=1\n",
    "NUM_LAYERS=1\n",
    "HIDDEN_SIZE=40\n",
    "DROPOUT=0\n",
    "\n",
    "num_epochs=30\n",
    "\n",
    "device=torch.device(\"cuda\")\n",
    "model_lstm_regr_energy = BasicLSTM(INPUT_SZ,HIDDEN_SIZE,NUM_CLASSES,NUM_LAYERS,dropout=DROPOUT,bidirectional=False)\n",
    "model_lstm_regr_energy.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "eb7c1dfd9cef8501831a78d439c6fb3d8def2ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t \t Training Loss 0.3643703665584326\n",
      "Epoch: 1 \t \t Training Loss 0.12344083345184724\n",
      "Epoch: 2 \t \t Training Loss 0.08158406801521778\n",
      "Epoch: 3 \t \t Training Loss 0.07134821452200413\n",
      "Epoch: 4 \t \t Training Loss 0.06677654758095741\n",
      "Epoch: 5 \t \t Training Loss 0.06584123941138387\n",
      "Epoch: 6 \t \t Training Loss 0.06580400622139375\n",
      "Epoch: 7 \t \t Training Loss 0.06435586729397376\n",
      "Epoch: 8 \t \t Training Loss 0.06435648476084073\n",
      "Epoch: 9 \t \t Training Loss 0.0641255568092068\n",
      "Epoch: 10 \t \t Training Loss 0.06466395097474258\n",
      "Epoch: 11 \t \t Training Loss 0.06388147997980316\n",
      "Epoch: 12 \t \t Training Loss 0.06372208893299103\n",
      "Epoch: 13 \t \t Training Loss 0.06440782686695457\n",
      "Epoch: 14 \t \t Training Loss 0.06371388382588823\n",
      "Epoch: 15 \t \t Training Loss 0.06335000460967422\n",
      "Epoch: 16 \t \t Training Loss 0.06419639196246862\n",
      "Epoch: 17 \t \t Training Loss 0.06353309362505873\n",
      "Epoch: 18 \t \t Training Loss 0.06396414929380019\n",
      "Epoch: 19 \t \t Training Loss 0.06306490597004692\n",
      "Epoch: 20 \t \t Training Loss 0.06329111708328128\n",
      "Epoch: 21 \t \t Training Loss 0.0627309181727469\n",
      "Epoch: 22 \t \t Training Loss 0.06312646825487415\n",
      "Epoch: 23 \t \t Training Loss 0.06258524550745885\n",
      "Epoch: 24 \t \t Training Loss 0.06277439851934712\n",
      "Epoch: 25 \t \t Training Loss 0.06223595701158047\n",
      "Epoch: 26 \t \t Training Loss 0.061996576841920614\n",
      "Epoch: 27 \t \t Training Loss 0.062415111965189375\n",
      "Epoch: 28 \t \t Training Loss 0.06284567217032115\n",
      "Epoch: 29 \t \t Training Loss 0.06172460123586158\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_lstm_regr_energy.parameters(),lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "    #always necessary. So we comment the following line.\n",
    "    #with torch.autograd(): \n",
    "    model_lstm_regr_energy.train()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    #train model in each epoch\n",
    "    for index,instance in enumerate(train_loader):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        #features,labels,lengths=instance\n",
    "        #print(instance)\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction_vec = model_lstm_regr_energy(features,lengths)\n",
    "        prediction_vec.to(device)\n",
    "        #print(prediction_vec.shape)\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        energy_labels=energy_labels.unsqueeze(1)\n",
    "        loss = criterion(prediction_vec,energy_labels)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "bae487fef24f4c4c7687190ee890b9937ae49d78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearnman's correlation for CNN-LSTM in validation set (predicting energy):  0.17821239577610523\n"
     ]
    }
   ],
   "source": [
    "model_lstm_regr_energy.eval()\n",
    "\n",
    "n_samples = 0\n",
    "SE = 0\n",
    "spearman=[]\n",
    "running_average_loss=0\n",
    "with torch.no_grad():\n",
    "    for index, instance in enumerate(val_loader):\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        \n",
    "    \n",
    "        out = model_lstm_regr_energy(features,lengths)\n",
    "        out = out.to(device)\n",
    "        #print(out)\n",
    "        #print(valence_labels)\n",
    "\n",
    "        energy_labels = energy_labels.unsqueeze(1)\n",
    "        E = energy_labels-out\n",
    "        SE = pow(E,2).sum().item() + SE\n",
    "        \n",
    "        n_samples+=features.shape[0]\n",
    "        \n",
    "        \n",
    "        spearman.append(stats.spearmanr(energy_labels.cpu().squeeze(),out.cpu().squeeze(),axis=0)[0])\n",
    "\n",
    "print(\"Spearnman's correlation for CNN-LSTM in validation set (predicting energy): \" , np.mean(spearman) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b4591b2eb1707e0d3c70e3664c41e11a82f0d285"
   },
   "source": [
    "2.CNN regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "89a1dfb8ce79cb0cbd373e10c0ad9966b148328d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense1): Linear(in_features=6720, out_features=500, bias=True)\n",
       "  (dense2): Linear(in_features=500, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs=35\n",
    "kernel_sz=3\n",
    "input_channels=1\n",
    "out_channels=1\n",
    "stride=2\n",
    "padding=2\n",
    "num_classes=10\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda\")\n",
    "\n",
    "model_cnn_regr_energy = ConvNet(input_channels,out_channels,kernel_sz,stride,padding ,num_classes)\n",
    "model_cnn_regr_energy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "c88757826fd269cc3c56f5ffd7c98277e667dad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t \t Training Loss 177.35119325543442\n",
      "Epoch: 1 \t \t Training Loss 3.373638480901718\n",
      "Epoch: 2 \t \t Training Loss 1.0650081398586433\n",
      "Epoch: 3 \t \t Training Loss 0.7032157567640146\n",
      "Epoch: 4 \t \t Training Loss 0.4943071448554595\n",
      "Epoch: 5 \t \t Training Loss 0.47897217112282914\n",
      "Epoch: 6 \t \t Training Loss 0.31252462168534595\n",
      "Epoch: 7 \t \t Training Loss 0.2680522110313177\n",
      "Epoch: 8 \t \t Training Loss 0.26080844054619473\n",
      "Epoch: 9 \t \t Training Loss 0.19785998668521643\n",
      "Epoch: 10 \t \t Training Loss 0.2781586078926921\n",
      "Epoch: 11 \t \t Training Loss 0.18920543727775416\n",
      "Epoch: 12 \t \t Training Loss 0.2523165137196581\n",
      "Epoch: 13 \t \t Training Loss 0.23425604573761424\n",
      "Epoch: 14 \t \t Training Loss 0.11459517246112227\n",
      "Epoch: 15 \t \t Training Loss 0.11660260055214167\n",
      "Epoch: 16 \t \t Training Loss 0.10038935951888561\n",
      "Epoch: 17 \t \t Training Loss 0.07174427807331085\n",
      "Epoch: 18 \t \t Training Loss 0.06011285989855727\n",
      "Epoch: 19 \t \t Training Loss 0.051906381733715534\n",
      "Epoch: 20 \t \t Training Loss 0.04695371041695277\n",
      "Epoch: 21 \t \t Training Loss 0.06684322523263593\n",
      "Epoch: 22 \t \t Training Loss 0.049618507347380124\n",
      "Epoch: 23 \t \t Training Loss 0.05197525893648466\n",
      "Epoch: 24 \t \t Training Loss 0.06806813483126462\n",
      "Epoch: 25 \t \t Training Loss 0.0501782502202938\n",
      "Epoch: 26 \t \t Training Loss 0.05339984797562162\n",
      "Epoch: 27 \t \t Training Loss 0.05483927422513565\n",
      "Epoch: 28 \t \t Training Loss 0.062294179728875555\n",
      "Epoch: 29 \t \t Training Loss 0.038801467744633555\n",
      "Epoch: 30 \t \t Training Loss 0.038623026378142335\n",
      "Epoch: 31 \t \t Training Loss 0.041142027669896684\n",
      "Epoch: 32 \t \t Training Loss 0.04109124944079667\n",
      "Epoch: 33 \t \t Training Loss 0.04078386599818865\n",
      "Epoch: 34 \t \t Training Loss 0.03087596835878988\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_regr_energy.parameters())\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "    #always necessary. So we comment the following line.\n",
    "    #with torch.autograd(): \n",
    "    model_cnn_regr_energy.train()\n",
    "    #scheduler.step()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    #train model in each epoch\n",
    "    for index,instance in enumerate(train_loader):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        #features,labels,lengths=instance\n",
    "        \n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction_vec = model_cnn_regr_energy(features,lengths)\n",
    "        prediction_vec.to(device)\n",
    "        \n",
    "        \n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        energy_labels = energy_labels.unsqueeze(1)\n",
    "        \n",
    "        loss = criterion(prediction_vec,energy_labels)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "4a1b9683e4929d5f96ddfb362b88a8ef827ecb8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearnman's correlation for CNN-2d in validation set (predicting energy):  0.5819362912855087\n"
     ]
    }
   ],
   "source": [
    "model_cnn_regr_energy.eval()\n",
    "\n",
    "n_samples = 0\n",
    "SE = 0\n",
    "spearman=[]\n",
    "running_average_loss=0\n",
    "with torch.no_grad():\n",
    "    for index, instance in enumerate(val_loader):\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        \n",
    "    \n",
    "        out = model_cnn_regr_energy(features,lengths)\n",
    "        out = out.to(device)\n",
    "        #print(out)\n",
    "        #print(valence_labels)\n",
    "\n",
    "        energy_labels = energy_labels.unsqueeze(1)\n",
    "        E = energy_labels-out\n",
    "        SE = pow(E,2).sum().item() + SE\n",
    "        \n",
    "        n_samples+=features.shape[0]\n",
    "        \n",
    "        spearman.append(stats.spearmanr(energy_labels.cpu().squeeze(),out.cpu().squeeze(),axis=0)[0])\n",
    "\n",
    "print(\"Spearnman's correlation for CNN-2d in validation set (predicting energy): \" , np.mean(spearman) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "036d270b657ba5adcce175097e046a9949c39479"
   },
   "source": [
    "3.CNN-LSTM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "925d30454814a2cc0ef46a2a36f68d63fcf44243"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTM(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv1d(140, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(512, 20, batch_first=True)\n",
       "  (hidden2output): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_epochs=35\n",
    "kernel_sz=3\n",
    "input_channels=140\n",
    "out_channels=140\n",
    "stride=1\n",
    "padding=1\n",
    "num_classes=1\n",
    "\n",
    "INPUT_SZ=512\n",
    "NUM_CLASSES=1\n",
    "NUM_LAYERS=1\n",
    "HIDDEN_SIZE=20\n",
    "DROPOUT=0\n",
    "\n",
    "device=torch.device(\"cuda\")\n",
    "model_cnn_lstm_regr_energy = ConvLSTM(input_channels,out_channels,kernel_sz,stride,padding ,num_classes,INPUT_SZ,HIDDEN_SIZE,NUM_CLASSES,NUM_LAYERS,dropout=DROPOUT,bidirectional=False)\n",
    "model_cnn_lstm_regr_energy.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "e7565e64f10bd2e3e014f4ff135bf5fc8ac36ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t \t Training Loss 0.3674344631532828\n",
      "Epoch: 1 \t \t Training Loss 0.3681592463205258\n",
      "Epoch: 2 \t \t Training Loss 0.3695120153327783\n",
      "Epoch: 3 \t \t Training Loss 0.36940086881319684\n",
      "Epoch: 4 \t \t Training Loss 0.36336606554687023\n",
      "Epoch: 5 \t \t Training Loss 0.36706822117169696\n",
      "Epoch: 6 \t \t Training Loss 0.36838410422205925\n",
      "Epoch: 7 \t \t Training Loss 0.3669094070792198\n",
      "Epoch: 8 \t \t Training Loss 0.36291499932607013\n",
      "Epoch: 9 \t \t Training Loss 0.364241989950339\n",
      "Epoch: 10 \t \t Training Loss 0.3668184665342172\n",
      "Epoch: 11 \t \t Training Loss 0.3707256888349851\n",
      "Epoch: 12 \t \t Training Loss 0.3655406671265761\n",
      "Epoch: 13 \t \t Training Loss 0.36597001925110817\n",
      "Epoch: 14 \t \t Training Loss 0.36448265115420025\n",
      "Epoch: 15 \t \t Training Loss 0.36805927256743115\n",
      "Epoch: 16 \t \t Training Loss 0.36685224746664363\n",
      "Epoch: 17 \t \t Training Loss 0.3685210471351941\n",
      "Epoch: 18 \t \t Training Loss 0.3679059228549401\n",
      "Epoch: 19 \t \t Training Loss 0.36829695974787074\n",
      "Epoch: 20 \t \t Training Loss 0.36794327447811764\n",
      "Epoch: 21 \t \t Training Loss 0.365855789432923\n",
      "Epoch: 22 \t \t Training Loss 0.36657712298134965\n",
      "Epoch: 23 \t \t Training Loss 0.3638324687878291\n",
      "Epoch: 24 \t \t Training Loss 0.3653421128789584\n",
      "Epoch: 25 \t \t Training Loss 0.3693582055469354\n",
      "Epoch: 26 \t \t Training Loss 0.36585793520013493\n",
      "Epoch: 27 \t \t Training Loss 0.36792322744925815\n",
      "Epoch: 28 \t \t Training Loss 0.3651768739024798\n",
      "Epoch: 29 \t \t Training Loss 0.3686611553033193\n",
      "Epoch: 30 \t \t Training Loss 0.3637009995679061\n",
      "Epoch: 31 \t \t Training Loss 0.36551718041300774\n",
      "Epoch: 32 \t \t Training Loss 0.3706091567873955\n",
      "Epoch: 33 \t \t Training Loss 0.36619550983111065\n",
      "Epoch: 34 \t \t Training Loss 0.36769446978966397\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_regr_energy.parameters())\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "    #always necessary. So we comment the following line.\n",
    "    #with torch.autograd(): \n",
    "    model_cnn_lstm_regr_energy.train()\n",
    "    #scheduler.step()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    #train model in each epoch\n",
    "    for index,instance in enumerate(train_loader):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        #features,labels,lengths=instance\n",
    "        \n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction_vec = model_cnn_lstm_regr_energy(features,lengths)\n",
    "        prediction_vec.to(device)\n",
    "        \n",
    "        \n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        energy_labels = energy_labels.unsqueeze(1)\n",
    "        \n",
    "        loss = criterion(prediction_vec,energy_labels)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "24cba6c3dc2673c95ead3b3f3dcaf07e538df2f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearnman's correlation for CNN-LSTM in validation set (predicting energy):  0.2440124449706023\n"
     ]
    }
   ],
   "source": [
    "model_cnn_lstm_regr_energy.eval()\n",
    "\n",
    "n_samples = 0\n",
    "SE = 0\n",
    "spearman=[]\n",
    "running_average_loss=0\n",
    "with torch.no_grad():\n",
    "    for index, instance in enumerate(val_loader):\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        \n",
    "    \n",
    "        out = model_cnn_lstm_regr_energy(features,lengths)\n",
    "        out = out.to(device)\n",
    "        #print(out)\n",
    "        #print(valence_labels)\n",
    "\n",
    "        energy_labels = energy_labels.unsqueeze(1)\n",
    "        E = energy_labels-out\n",
    "        SE = pow(E,2).sum().item() + SE\n",
    "        \n",
    "        n_samples+=features.shape[0]\n",
    "        \n",
    "        spearman.append(stats.spearmanr(energy_labels.cpu().squeeze(),out.cpu().squeeze(),axis=0)[0])\n",
    "\n",
    "print(\"Spearnman's correlation for CNN-LSTM in validation set (predicting energy): \" , np.mean(spearman) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9c2b156a582f44fe8dcb261bc2ef8c2ba012a63"
   },
   "source": [
    "**REGRESSION FOR DANCEABILITY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd9a5018aca7e4eed2d11f8c4561a316e0592ad4"
   },
   "source": [
    "1.LSTM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "c3f1e26af853104c477e98a55e813389ee151370"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicLSTM(\n",
       "  (lstm): LSTM(140, 40, batch_first=True)\n",
       "  (hidden2output): Linear(in_features=40, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SZ=140\n",
    "NUM_CLASSES=1\n",
    "NUM_LAYERS=1\n",
    "HIDDEN_SIZE=40\n",
    "DROPOUT=0\n",
    "\n",
    "num_epochs=30\n",
    "\n",
    "device=torch.device(\"cuda\")\n",
    "model_lstm_regr_dance = BasicLSTM(INPUT_SZ,HIDDEN_SIZE,NUM_CLASSES,NUM_LAYERS,dropout=DROPOUT,bidirectional=False)\n",
    "model_lstm_regr_dance.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "a4bf4f5e7d37c2d962cb01b2f84e0f231631bb1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t \t Training Loss 0.036275331784660615\n",
      "Epoch: 1 \t \t Training Loss 0.032621978859727584\n",
      "Epoch: 2 \t \t Training Loss 0.031108517898246646\n",
      "Epoch: 3 \t \t Training Loss 0.03075908978159229\n",
      "Epoch: 4 \t \t Training Loss 0.030993095676725108\n",
      "Epoch: 5 \t \t Training Loss 0.030176676421736676\n",
      "Epoch: 6 \t \t Training Loss 0.03010942996479571\n",
      "Epoch: 7 \t \t Training Loss 0.02989776968024671\n",
      "Epoch: 8 \t \t Training Loss 0.029317428125068545\n",
      "Epoch: 9 \t \t Training Loss 0.029301957770561177\n",
      "Epoch: 10 \t \t Training Loss 0.029365537610525887\n",
      "Epoch: 11 \t \t Training Loss 0.02909840705494086\n",
      "Epoch: 12 \t \t Training Loss 0.02921866726440688\n",
      "Epoch: 13 \t \t Training Loss 0.02925003265651564\n",
      "Epoch: 14 \t \t Training Loss 0.029179397543581825\n",
      "Epoch: 15 \t \t Training Loss 0.02904721659918626\n",
      "Epoch: 16 \t \t Training Loss 0.028896586154587567\n",
      "Epoch: 17 \t \t Training Loss 0.02926769860399266\n",
      "Epoch: 18 \t \t Training Loss 0.028924169872576993\n",
      "Epoch: 19 \t \t Training Loss 0.028753722629820306\n",
      "Epoch: 20 \t \t Training Loss 0.028842537353436153\n",
      "Epoch: 21 \t \t Training Loss 0.028786376079854865\n",
      "Epoch: 22 \t \t Training Loss 0.028932300861924887\n",
      "Epoch: 23 \t \t Training Loss 0.029152086935937405\n",
      "Epoch: 24 \t \t Training Loss 0.02873981697484851\n",
      "Epoch: 25 \t \t Training Loss 0.02899605268612504\n",
      "Epoch: 26 \t \t Training Loss 0.028730362265681226\n",
      "Epoch: 27 \t \t Training Loss 0.028613964871813852\n",
      "Epoch: 28 \t \t Training Loss 0.028645642024154466\n",
      "Epoch: 29 \t \t Training Loss 0.028514767686525982\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model_lstm_regr_dance.parameters(),lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "    #always necessary. So we comment the following line.\n",
    "    #with torch.autograd(): \n",
    "    model_lstm_regr_dance.train()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    #train model in each epoch\n",
    "    for index,instance in enumerate(train_loader):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        #features,labels,lengths=instance\n",
    "        #print(instance)\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction_vec = model_lstm_regr_dance(features,lengths)\n",
    "        prediction_vec.to(device)\n",
    "        #print(prediction_vec.shape)\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        dance_labels=dance_labels.unsqueeze(1)\n",
    "        loss = criterion(prediction_vec,dance_labels)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "beb98bc04079736d7a778e827e1a6bb72c076263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearnman's correlation for LSTM in validation set (predicting dance):  0.09592557532326672\n"
     ]
    }
   ],
   "source": [
    "model_lstm_regr_dance.eval()\n",
    "\n",
    "n_samples = 0\n",
    "SE = 0\n",
    "spearman=[]\n",
    "running_average_loss=0\n",
    "with torch.no_grad():\n",
    "    for index, instance in enumerate(val_loader):\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        \n",
    "    \n",
    "        out = model_lstm_regr_dance(features,lengths)\n",
    "        out = out.to(device)\n",
    "        #print(out)\n",
    "        #print(valence_labels)\n",
    "\n",
    "        dance_labels = dance_labels.unsqueeze(1)\n",
    "        E = dance_labels-out\n",
    "        SE = pow(E,2).sum().item() + SE\n",
    "        #print(SE)\n",
    "        n_samples+=features.shape[0]\n",
    "        \n",
    "        \n",
    "        spearman.append(stats.spearmanr(dance_labels.cpu().squeeze(),out.cpu().squeeze(),axis=0)[0])\n",
    "\n",
    "print(\"Spearnman's correlation for LSTM in validation set (predicting dance): \" , np.mean(spearman) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20a8070ec5529dbfdadb5a64f8269676cb5f3fc6"
   },
   "source": [
    "CNN regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "84e1bd0d57b6dc2c0f938d84956dd1bf04889f1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense1): Linear(in_features=6720, out_features=500, bias=True)\n",
       "  (dense2): Linear(in_features=500, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs=35\n",
    "kernel_sz=3\n",
    "input_channels=1\n",
    "out_channels=1\n",
    "stride=2\n",
    "padding=2\n",
    "num_classes=10\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda\")\n",
    "\n",
    "model_cnn_regr_dance = ConvNet(input_channels,out_channels,kernel_sz,stride,padding ,num_classes)\n",
    "model_cnn_regr_dance.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "bb134477e4ef2ba7e4ccfb6a011cacf2a2436dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t \t Training Loss 257.1424967497587\n",
      "Epoch: 1 \t \t Training Loss 4.9612445048987865\n",
      "Epoch: 2 \t \t Training Loss 0.6566959147651991\n",
      "Epoch: 3 \t \t Training Loss 0.24055650861312947\n",
      "Epoch: 4 \t \t Training Loss 0.1455674385651946\n",
      "Epoch: 5 \t \t Training Loss 0.10710497759282589\n",
      "Epoch: 6 \t \t Training Loss 0.08736992937823136\n",
      "Epoch: 7 \t \t Training Loss 0.06791758498487373\n",
      "Epoch: 8 \t \t Training Loss 0.06611964579982062\n",
      "Epoch: 9 \t \t Training Loss 0.05250475757444898\n",
      "Epoch: 10 \t \t Training Loss 0.05025319972385963\n",
      "Epoch: 11 \t \t Training Loss 0.05295970904019972\n",
      "Epoch: 12 \t \t Training Loss 0.03926408484888574\n",
      "Epoch: 13 \t \t Training Loss 0.04084403386029104\n",
      "Epoch: 14 \t \t Training Loss 0.03828893912335237\n",
      "Epoch: 15 \t \t Training Loss 0.03688136961621543\n",
      "Epoch: 16 \t \t Training Loss 0.0377623342598478\n",
      "Epoch: 17 \t \t Training Loss 0.03354039730038494\n",
      "Epoch: 18 \t \t Training Loss 0.03199771939155956\n",
      "Epoch: 19 \t \t Training Loss 0.027816312193560105\n",
      "Epoch: 20 \t \t Training Loss 0.026990294534092147\n",
      "Epoch: 21 \t \t Training Loss 0.03449454185708115\n",
      "Epoch: 22 \t \t Training Loss 0.02844840435621639\n",
      "Epoch: 23 \t \t Training Loss 0.028979445652415354\n",
      "Epoch: 24 \t \t Training Loss 0.02327630117846032\n",
      "Epoch: 25 \t \t Training Loss 0.020916752517223358\n",
      "Epoch: 26 \t \t Training Loss 0.019387031439691782\n",
      "Epoch: 27 \t \t Training Loss 0.02321108019289871\n",
      "Epoch: 28 \t \t Training Loss 0.019582091908281047\n",
      "Epoch: 29 \t \t Training Loss 0.023715858114883304\n",
      "Epoch: 30 \t \t Training Loss 0.020737181456449132\n",
      "Epoch: 31 \t \t Training Loss 0.023937701402852934\n",
      "Epoch: 32 \t \t Training Loss 0.02635567115309338\n",
      "Epoch: 33 \t \t Training Loss 0.020866400562226772\n",
      "Epoch: 34 \t \t Training Loss 0.01888330579580118\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_regr_dance.parameters())\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "    #always necessary. So we comment the following line.\n",
    "    #with torch.autograd(): \n",
    "    model_cnn_regr_dance.train()\n",
    "    #scheduler.step()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    #train model in each epoch\n",
    "    for index,instance in enumerate(train_loader):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        #features,labels,lengths=instance\n",
    "        \n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction_vec = model_cnn_regr_dance(features,lengths)\n",
    "        prediction_vec.to(device)\n",
    "        \n",
    "        \n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        dance_labels = dance_labels.unsqueeze(1)\n",
    "        \n",
    "        loss = criterion(prediction_vec,dance_labels)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "d8c6508bfa5bbef94945f88f63dfb07334b85a53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearnman's correlation for CNN in validation set (predicting dance):  0.5619338200866792\n"
     ]
    }
   ],
   "source": [
    "model_cnn_regr_dance.eval()\n",
    "\n",
    "n_samples = 0\n",
    "SE = 0\n",
    "spearman=[]\n",
    "running_average_loss=0\n",
    "with torch.no_grad():\n",
    "    for index, instance in enumerate(val_loader):\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        \n",
    "    \n",
    "        out = model_cnn_regr_dance(features,lengths)\n",
    "        out = out.to(device)\n",
    "        #print(out)\n",
    "        #print(valence_labels)\n",
    "\n",
    "        dance_labels = dance_labels.unsqueeze(1)\n",
    "        E = dance_labels-out\n",
    "        SE = pow(E,2).sum().item() + SE\n",
    "        \n",
    "        n_samples+=features.shape[0]\n",
    "        \n",
    "        \n",
    "        spearman.append(stats.spearmanr(dance_labels.cpu().squeeze(),out.cpu().squeeze(),axis=0)[0])\n",
    "\n",
    "print(\"Spearnman's correlation for CNN in validation set (predicting dance): \" , np.mean(spearman) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2af8f66ca3a46a522e8476152e3f164590e9dd45"
   },
   "source": [
    "3. CNN-LSTM regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "2cb02f8463d3fcd2adc4f655934d42d042468078"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLSTM(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv1d(140, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lstm): LSTM(512, 20, batch_first=True)\n",
       "  (hidden2output): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_epochs=35\n",
    "kernel_sz=3\n",
    "input_channels=140\n",
    "out_channels=140\n",
    "stride=1\n",
    "padding=1\n",
    "num_classes=1\n",
    "\n",
    "INPUT_SZ=512\n",
    "NUM_CLASSES=1\n",
    "NUM_LAYERS=1\n",
    "HIDDEN_SIZE=20\n",
    "DROPOUT=0\n",
    "\n",
    "device=torch.device(\"cuda\")\n",
    "model_cnn_lstm_regr_dance = ConvLSTM(input_channels,out_channels,kernel_sz,stride,padding ,num_classes,INPUT_SZ,HIDDEN_SIZE,NUM_CLASSES,NUM_LAYERS,dropout=DROPOUT,bidirectional=False)\n",
    "model_cnn_lstm_regr_dance.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "6e4b8f454ef2b14ea03ff02a8cb4ce23bee177cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t \t Training Loss 0.3653145854671796\n",
      "Epoch: 1 \t \t Training Loss 0.3612513455251853\n",
      "Epoch: 2 \t \t Training Loss 0.36467402925093967\n",
      "Epoch: 3 \t \t Training Loss 0.36538828164339066\n",
      "Epoch: 4 \t \t Training Loss 0.36688853427767754\n",
      "Epoch: 5 \t \t Training Loss 0.36514253293474513\n",
      "Epoch: 6 \t \t Training Loss 0.36520153656601906\n",
      "Epoch: 7 \t \t Training Loss 0.36385059729218483\n",
      "Epoch: 8 \t \t Training Loss 0.36502644295493764\n",
      "Epoch: 9 \t \t Training Loss 0.36722215761741\n",
      "Epoch: 10 \t \t Training Loss 0.3678033413986365\n",
      "Epoch: 11 \t \t Training Loss 0.3649626597762108\n",
      "Epoch: 12 \t \t Training Loss 0.3663378991186619\n",
      "Epoch: 13 \t \t Training Loss 0.3624142222106457\n",
      "Epoch: 14 \t \t Training Loss 0.3665134757757187\n",
      "Epoch: 15 \t \t Training Loss 0.3660081202785174\n",
      "Epoch: 16 \t \t Training Loss 0.3646719828248024\n",
      "Epoch: 17 \t \t Training Loss 0.3634176639219125\n",
      "Epoch: 18 \t \t Training Loss 0.365891953309377\n",
      "Epoch: 19 \t \t Training Loss 0.36479418476422626\n",
      "Epoch: 20 \t \t Training Loss 0.36295539264877635\n",
      "Epoch: 21 \t \t Training Loss 0.36321931208173436\n",
      "Epoch: 22 \t \t Training Loss 0.36866729830702144\n",
      "Epoch: 23 \t \t Training Loss 0.36704714968800545\n",
      "Epoch: 24 \t \t Training Loss 0.3707428214450677\n",
      "Epoch: 25 \t \t Training Loss 0.36667051414648694\n",
      "Epoch: 26 \t \t Training Loss 0.36406775812307995\n",
      "Epoch: 27 \t \t Training Loss 0.3637923449277878\n",
      "Epoch: 28 \t \t Training Loss 0.36510981743534404\n",
      "Epoch: 29 \t \t Training Loss 0.36847057566046715\n",
      "Epoch: 30 \t \t Training Loss 0.3663945148388545\n",
      "Epoch: 31 \t \t Training Loss 0.36549463123083115\n",
      "Epoch: 32 \t \t Training Loss 0.3672523299853007\n",
      "Epoch: 33 \t \t Training Loss 0.3637808958689372\n",
      "Epoch: 34 \t \t Training Loss 0.36709358046452206\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_regr_dance.parameters())\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "    #always necessary. So we comment the following line.\n",
    "    #with torch.autograd(): \n",
    "    model_cnn_lstm_regr_dance.train()\n",
    "    #scheduler.step()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    #train model in each epoch\n",
    "    for index,instance in enumerate(train_loader):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        #features,labels,lengths=instance\n",
    "        \n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction_vec = model_cnn_lstm_regr_dance(features,lengths)\n",
    "        prediction_vec.to(device)\n",
    "        \n",
    "        \n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        dance_labels = dance_labels.unsqueeze(1)\n",
    "        \n",
    "        loss = criterion(prediction_vec,dance_labels)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "3728e7daf85aadc751bf8aa96d0ddc958769d864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearnman's correlation for CNN-LSTM in validation set (predicting danceability):  -0.03544197194074701\n"
     ]
    }
   ],
   "source": [
    "model_cnn_lstm_regr_dance.eval()\n",
    "\n",
    "n_samples = 0\n",
    "SE = 0\n",
    "spearman = []\n",
    "\n",
    "running_average_loss=0\n",
    "with torch.no_grad():\n",
    "    for index, instance in enumerate(val_loader):\n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        \n",
    "    \n",
    "        out = model_cnn_lstm_regr_dance(features,lengths)\n",
    "        out = out.to(device)\n",
    "        #print(out)\n",
    "        #print(valence_labels)\n",
    "\n",
    "        dance_labels = dance_labels.unsqueeze(1)\n",
    "        #E = dance_labels-out\n",
    "        #SE = pow(E,2).sum().item() + SE\n",
    "        #n_samples+=features.shape[0]\n",
    "        \n",
    "        spearman.append(stats.spearmanr(dance_labels.cpu().squeeze(),out.cpu().squeeze(),axis=0)[0])\n",
    "\n",
    "print(\"Spearnman's correlation for CNN-LSTM in validation set (predicting danceability): \" , np.mean(spearman) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "1ce90be411ad80f2efa8f883de5edecb1828515c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "ce31f0a2510dc56536a9b954924a1270c4aa9b02"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "d122d9d6d915fd5126dab2f346af7f6b62309b95"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
