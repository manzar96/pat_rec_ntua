{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "class_mapping = {\n",
    "    'Rock': 'Rock',\n",
    "    'Psych-Rock': 'Rock',\n",
    "    'Indie-Rock': None,\n",
    "    'Post-Rock': 'Rock',\n",
    "    'Psych-Folk': 'Folk',\n",
    "    'Folk': 'Folk',\n",
    "    'Metal': 'Metal',\n",
    "    'Punk': 'Metal',\n",
    "    'Post-Punk': None,\n",
    "    'Trip-Hop': 'Trip-Hop',\n",
    "    'Pop': 'Pop',\n",
    "    'Electronic': 'Electronic',\n",
    "    'Hip-Hop': 'Hip-Hop',\n",
    "    'Classical': 'Classical',\n",
    "    'Blues': 'Blues',\n",
    "    'Chiptune': 'Electronic',\n",
    "    'Jazz': 'Jazz',\n",
    "    'Soundtrack': None,\n",
    "    'International': None,\n",
    "    'Old-Time': None\n",
    "}\n",
    "\n",
    "\n",
    "def torch_train_val_split(\n",
    "        dataset, batch_train, batch_eval,\n",
    "        val_size=.2, shuffle=True, seed=42):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    val_split = int(np.floor(val_size * dataset_size))\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices = indices[val_split:]\n",
    "    val_indices = indices[:val_split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset,\n",
    "                              batch_size=batch_train,\n",
    "                              sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset,\n",
    "                            batch_size=batch_eval,\n",
    "                            sampler=val_sampler)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def read_spectrogram(spectrogram_file, chroma=True):\n",
    "    with gzip.GzipFile(spectrogram_file, 'r') as f:\n",
    "        spectrograms = np.load(f)\n",
    "    # spectrograms contains a fused mel spectrogram and chromagram\n",
    "    # Decompose as follows\n",
    "    return spectrograms.T\n",
    "\n",
    "\n",
    "class LabelTransformer(LabelEncoder):\n",
    "    def inverse(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).inverse_transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).inverse_transform([y])\n",
    "\n",
    "    def transform(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).transform([y])\n",
    "\n",
    "        \n",
    "class PaddingTransform(object):\n",
    "    def __init__(self, max_length, padding_value=0):\n",
    "        self.max_length = max_length\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "    def __call__(self, s):\n",
    "        if len(s) == self.max_length:\n",
    "            return s\n",
    "\n",
    "        if len(s) > self.max_length:\n",
    "            return s[:self.max_length]\n",
    "\n",
    "        if len(s) < self.max_length:\n",
    "            s1 = copy.deepcopy(s)\n",
    "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
    "            s1 = np.vstack((s1, pad))\n",
    "            return s1\n",
    "\n",
    "        \n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, path, class_mapping=None, train=True, max_length=-1):\n",
    "        t = 'train' if train else 'test'\n",
    "        p = os.path.join(path, t)\n",
    "        self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
    "        self.files, labels = self.get_files_labels(self.index, class_mapping)\n",
    "        #print(self.files)\n",
    "        \n",
    "        self.feats = [read_spectrogram(os.path.join(p, f+\".fused.full.npy.gz\")) for f in self.files]\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "        #self.label_transformer = LabelTransformer()\n",
    "        #if isinstance(labels, (list, tuple)):\n",
    "            #self.labels = np.array(self.label_transformer.fit_transform(labels)).astype('int64')\n",
    "        self.labels=labels\n",
    "    def get_files_labels(self, txt, class_mapping):\n",
    "        with open(txt, 'r') as fd:\n",
    "            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n",
    "            \n",
    "        files, labels = [], []\n",
    "        for l in lines:\n",
    "            l=l[0].split(\",\")\n",
    "            b=l[1:]\n",
    "            b = list(map(float,b))\n",
    "            files.append(l[0])\n",
    "            \n",
    "            labels.append(b)\n",
    "        return files, labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        l = min(self.lengths[item], self.max_length)\n",
    "        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d6e7dbe2100e40b3a37c1314bd9cb2f1274148b0"
   },
   "outputs": [],
   "source": [
    "BATCH_SZ=32\n",
    "\n",
    "specs = SpectrogramDataset('../input/data/data/multitask_dataset/', train=True, class_mapping=class_mapping, max_length=-1)\n",
    "train_loader, val_loader = torch_train_val_split(specs, BATCH_SZ ,BATCH_SZ, val_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "8d8da0985c9f5303d6c77b02de92ec45a0cfab8b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy import stats\n",
    "\n",
    "class ConvNetMulty3(nn.Module):\n",
    "    def __init__(self,input_channels,out_channels,kernel_sz,stride,padding, num_classes):\n",
    "        super(ConvNetMulty3, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 16, kernel_size=(5,5), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(5,5), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32 , 64 , kernel_size=(3,3), stride=1, padding=1),\n",
    "            \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer4_task1 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3), stride=2, padding=1),\n",
    "            \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        )\n",
    "        self.layer4_task2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3), stride=2, padding=1),\n",
    "            \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        )\n",
    "        self.layer4_task3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(3,3), stride=2, padding=1),\n",
    "            \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "           \n",
    "            nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        )\n",
    "        \n",
    "        #self.dense1_task1= nn.Linear(6720,500) \n",
    "        #self.dense2_task1 = nn.Linear(500,50)\n",
    "        #self.dense3_task1 = nn.Linear(50,1)\n",
    "        self.dense_task1 = nn.Sequential(\n",
    "            nn.Linear(6656,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(500,50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50,1),\n",
    "            \n",
    "        ) \n",
    "        \n",
    "        #self.dense1_task2= nn.Linear(6720,500) \n",
    "        #self.dense2_task2 = nn.Linear(500,50)\n",
    "        #self.dense3_task2 = nn.Linear(50,1)\n",
    "        self.dense_task2 = nn.Sequential(\n",
    "            nn.Linear(6656,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(500,50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50,1)\n",
    "        ) \n",
    "        \n",
    "        #self.dense1_task3= nn.Linear(6720,500) \n",
    "        #self.dense2_task3 = nn.Linear(500,50)\n",
    "        #self.dense3_task3 = nn.Linear(50,1)\n",
    "        self.dense_task3 = nn.Sequential(\n",
    "            nn.Linear(6656,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(500,50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50,1)\n",
    "        ) \n",
    "        \n",
    "    def forward(self, x,lengths):\n",
    "        #print(x.shape)\n",
    "        x = x.transpose(1, 2)\n",
    "        #print(x.shape)\n",
    "        x.unsqueeze_(1)\n",
    "        #print(x.shape)\n",
    "        out1 = self.layer1(x)\n",
    "        #print(out1.shape)\n",
    "        out2= self.layer2(out1)\n",
    "        #print(out2.shape)\n",
    "        out3= self.layer3(out2)\n",
    "        #print(out3.shape)\n",
    "        #out4= self.layer4(out3)\n",
    "        \n",
    "        out4_task1= self.layer4_task1(out3)\n",
    "        out4_task2= self.layer4_task2(out3)\n",
    "        out4_task3= self.layer4_task3(out3)\n",
    "        \n",
    "        #print(out4.shape)\n",
    "        out_flat_task1=out4_task1.reshape(-1,out4_task1.size(1)*out4_task1.size(2)*out4_task1.size(3))\n",
    "        out_flat_task2=out4_task2.reshape(-1,out4_task2.size(1)*out4_task2.size(2)*out4_task2.size(3))\n",
    "        out_flat_task3=out4_task3.reshape(-1,out4_task3.size(1)*out4_task3.size(2)*out4_task3.size(3))\n",
    "    \n",
    "        #out_flat=out4.reshape(-1,out4.size(1)*out4.size(2)*out4.size(3))\n",
    "        #print(out_flat.shape)\n",
    "        \n",
    "        \n",
    "        #implementing fully connected layers\n",
    "        \n",
    "        #hidden_out_task1 = self.dense1_task1(out_flat_task1)\n",
    "        #hidden_out2_task1 = self.dense2_task1(hidden_out_task1)\n",
    "        #final_out_task1 =  self.dense3_task1(hidden_out2_task1)\n",
    "        final_out_task1 = self.dense_task1(out_flat_task1)\n",
    "        \n",
    "        #hidden_out_task2 = self.dense1_task2(out_flat_task2)\n",
    "        #hidden_out2_task2 = self.dense2_task2(hidden_out_task2)\n",
    "        #final_out_task2 = self.dense3_task2(hidden_out2_task2)\n",
    "        final_out_task2 = self.dense_task2(out_flat_task2)\n",
    "        \n",
    "        #hidden_out_task3 = self.dense1_task3(out_flat_task3)\n",
    "        #hidden_out2_task3 = self.dense2_task3(hidden_out_task3)\n",
    "        #final_out_task3 = self.dense3_task3(hidden_out2_task3)\n",
    "        final_out_task3 = self.dense_task3(out_flat_task3)\n",
    "        \n",
    "        return final_out_task1,final_out_task2,final_out_task3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "2e90b52272a2c5152d26796c02317f3f20ec26a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNetMulty3(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4_task1): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4_task2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4_task3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense_task1): Sequential(\n",
       "    (0): Linear(in_features=6656, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=1000, out_features=500, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=500, out_features=50, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.5)\n",
       "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       "  (dense_task2): Sequential(\n",
       "    (0): Linear(in_features=6656, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=1000, out_features=500, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=500, out_features=50, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.5)\n",
       "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       "  (dense_task3): Sequential(\n",
       "    (0): Linear(in_features=6656, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=1000, out_features=500, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=500, out_features=50, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.5)\n",
       "    (9): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs=35\n",
    "kernel_sz=3\n",
    "input_channels=1\n",
    "out_channels=1\n",
    "stride=2\n",
    "padding=2\n",
    "num_classes=1\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda\")\n",
    "\n",
    "model_cnn_regr_multy3 = ConvNetMulty3(input_channels,out_channels,kernel_sz,stride,padding ,num_classes)\n",
    "model_cnn_regr_multy3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "00d6bb5d471932ce9801f4768e86ffc346f93533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t \t Training Loss 1.3707121403680906 0.14447759091854095 0.0428374744951725 0.061876825988292694\n",
      "Epoch: 1 \t \t Training Loss 0.2868082908292611 0.15440733730793 0.01638169400393963 0.01803939789533615\n",
      "Epoch: 2 \t \t Training Loss 0.2500380728807714 0.09336184710264206 0.09637004137039185 0.005706711206585169\n",
      "Epoch: 3 \t \t Training Loss 0.2449434573451678 0.0995127335190773 0.13985134661197662 0.04725595936179161\n",
      "Epoch: 4 \t \t Training Loss 0.21083492247594726 0.05170074477791786 0.05883922427892685 0.02560330741107464\n",
      "Epoch: 5 \t \t Training Loss 0.1998962356398503 0.05391919985413551 0.05393308401107788 0.006655864883214235\n",
      "Epoch: 6 \t \t Training Loss 0.21003466058108541 0.005336370784789324 0.1293434053659439 0.09535902738571167\n",
      "Epoch: 7 \t \t Training Loss 0.20595389190647337 0.11262175440788269 0.09753444790840149 0.024063611403107643\n",
      "Epoch: 8 \t \t Training Loss 0.18377308340536225 0.05901624634861946 0.04387233406305313 0.0344407819211483\n",
      "Epoch: 9 \t \t Training Loss 0.17609418431917825 0.12160073220729828 0.021329738199710846 0.011612894013524055\n",
      "Epoch: 10 \t \t Training Loss 0.17733196003569496 0.08466602861881256 0.14980988204479218 0.0006810552440583706\n",
      "Epoch: 11 \t \t Training Loss 0.18334388836390442 0.014757253229618073 0.08661968261003494 0.022118501365184784\n",
      "Epoch: 12 \t \t Training Loss 0.1673995384739505 0.013750802725553513 0.006311697885394096 0.10857489705085754\n",
      "Epoch: 13 \t \t Training Loss 0.15412183726827303 0.0028656432405114174 0.04474719613790512 0.02817726694047451\n",
      "Epoch: 14 \t \t Training Loss 0.15706880225075615 0.17441965639591217 0.06006540358066559 0.023591265082359314\n",
      "Epoch: 15 \t \t Training Loss 0.15980160940024588 0.13997606933116913 0.055370159447193146 0.0885152816772461\n",
      "Epoch: 16 \t \t Training Loss 0.15431913050512472 0.05344601348042488 0.06478752195835114 0.04198843985795975\n",
      "Epoch: 17 \t \t Training Loss 0.14617752635644543 0.0027448399923741817 0.05168595165014267 0.013882509432733059\n",
      "Epoch: 18 \t \t Training Loss 0.14220779202878475 0.12950773537158966 0.01434697862714529 0.03801948204636574\n",
      "Epoch: 19 \t \t Training Loss 0.15785225335922506 0.14228717982769012 0.06324172765016556 0.14815829694271088\n",
      "Epoch: 20 \t \t Training Loss 0.14986951442228424 0.22193840146064758 0.0531432144343853 0.031115872785449028\n",
      "Epoch: 21 \t \t Training Loss 0.14065094333555964 0.05756418779492378 0.07855154573917389 0.0018263673409819603\n",
      "Epoch: 22 \t \t Training Loss 0.13320890958938333 0.05489727854728699 0.052815958857536316 0.047301411628723145\n",
      "Epoch: 23 \t \t Training Loss 0.12442514590091175 0.02574954554438591 0.05348941683769226 0.006679918151348829\n",
      "Epoch: 24 \t \t Training Loss 0.13195871810118356 0.179582417011261 0.016137931495904922 0.041242703795433044\n",
      "Epoch: 25 \t \t Training Loss 0.12006130607591735 0.039272014051675797 0.011153286322951317 0.053388528525829315\n",
      "Epoch: 26 \t \t Training Loss 0.11703361446658771 0.050237420946359634 0.040805015712976456 0.03674419969320297\n",
      "Epoch: 27 \t \t Training Loss 0.1147404464168681 0.020253175869584084 0.05367189273238182 0.0037925573997199535\n",
      "Epoch: 28 \t \t Training Loss 0.11447415055914058 0.007708967197686434 0.020125605165958405 0.008079891093075275\n",
      "Epoch: 29 \t \t Training Loss 0.11644490021798345 0.13291561603546143 0.06040668115019798 0.04441167414188385\n",
      "Epoch: 30 \t \t Training Loss 0.11798072171707948 0.21163707971572876 0.08921428769826889 9.985869110096246e-05\n",
      "Epoch: 31 \t \t Training Loss 0.10571455106967026 0.057355623692274094 0.01522184070199728 0.0015926776686683297\n",
      "Epoch: 32 \t \t Training Loss 0.11248542678852876 0.1745414286851883 0.022374870255589485 0.034655194729566574\n",
      "Epoch: 33 \t \t Training Loss 0.11141541000041696 0.14151838421821594 0.12805265188217163 0.002778333146125078\n",
      "Epoch: 34 \t \t Training Loss 0.10621296531624264 0.021328337490558624 0.005497475620359182 0.017878027632832527\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_cnn_regr_multy3.parameters(),weight_decay=0.001)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #no need to set requires_grad=True for parameters(weights) as it done by default. Also for input requires_grad is not\n",
    "    #always necessary. So we comment the following line.\n",
    "    #with torch.autograd(): \n",
    "    model_cnn_regr_multy3.train()\n",
    "    #scheduler.step()\n",
    "    running_average_loss = 0\n",
    "\n",
    "    #train model in each epoch\n",
    "    for index,instance in enumerate(train_loader):\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        #features,labels,lengths=instance\n",
    "        \n",
    "        features = instance[:][0].to(device)\n",
    "        labels = instance[:][1]\n",
    "        valence_labels = labels[0].type(torch.FloatTensor).to(device)\n",
    "        energy_labels = labels[1].type(torch.FloatTensor).to(device)\n",
    "        dance_labels = labels[2].type(torch.FloatTensor).to(device)\n",
    "        lengths = instance[:][2].to(device)\n",
    "        features = features.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step 3. Run our forward pass.\n",
    "        prediction_vec_task1,prediction_vec_task2,prediction_vec_task3 = model_cnn_regr_multy3(features,lengths)\n",
    "        prediction_vec_task1.to(device)\n",
    "        prediction_vec_task2.to(device)\n",
    "        prediction_vec_task3.to(device)\n",
    "        \n",
    "        \n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        valence_labels = valence_labels.unsqueeze(1)\n",
    "        energy_labels = energy_labels.unsqueeze(1)\n",
    "        dance_labels = dance_labels.unsqueeze(1)\n",
    "        \n",
    "        loss1 = criterion(prediction_vec_task1,valence_labels)\n",
    "        loss2 = criterion(prediction_vec_task2,energy_labels)\n",
    "        loss3 = criterion(prediction_vec_task3,dance_labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss=loss1+loss2+loss3\n",
    "        \n",
    "        #print(loss1,\"  \",loss2,\"  \",loss3)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_average_loss += loss.detach().item()\n",
    "    print(\"Epoch: {} \\t \\t Training Loss {}\".format(epoch, float(running_average_loss) / (index + 1)),loss1.item(),loss2.item(),loss3.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "faa5cf3189516682c227e1a1355c09723daf6294"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import SubsetRandomSampler, DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "class_mapping = {\n",
    "    'Rock': 'Rock',\n",
    "    'Psych-Rock': 'Rock',\n",
    "    'Indie-Rock': None,\n",
    "    'Post-Rock': 'Rock',\n",
    "    'Psych-Folk': 'Folk',\n",
    "    'Folk': 'Folk',\n",
    "    'Metal': 'Metal',\n",
    "    'Punk': 'Metal',\n",
    "    'Post-Punk': None,\n",
    "    'Trip-Hop': 'Trip-Hop',\n",
    "    'Pop': 'Pop',\n",
    "    'Electronic': 'Electronic',\n",
    "    'Hip-Hop': 'Hip-Hop',\n",
    "    'Classical': 'Classical',\n",
    "    'Blues': 'Blues',\n",
    "    'Chiptune': 'Electronic',\n",
    "    'Jazz': 'Jazz',\n",
    "    'Soundtrack': None,\n",
    "    'International': None,\n",
    "    'Old-Time': None\n",
    "}\n",
    "\n",
    "\n",
    "def torch_train_val_split(\n",
    "        dataset, batch_train, batch_eval,\n",
    "        val_size=.2, shuffle=True, seed=42):\n",
    "    # Creating data indices for training and validation splits:\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    val_split = int(np.floor(val_size * dataset_size))\n",
    "    if shuffle:\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices = indices[val_split:]\n",
    "    val_indices = indices[:val_split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "    train_loader = DataLoader(dataset,\n",
    "                              batch_size=batch_train,\n",
    "                              sampler=train_sampler)\n",
    "    val_loader = DataLoader(dataset,\n",
    "                            batch_size=batch_eval,\n",
    "                            sampler=val_sampler)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def read_spectrogram(spectrogram_file, chroma=True):\n",
    "    with gzip.GzipFile(spectrogram_file, 'r') as f:\n",
    "        spectrograms = np.load(f)\n",
    "    # spectrograms contains a fused mel spectrogram and chromagram\n",
    "    # Decompose as follows\n",
    "    return spectrograms.T\n",
    "\n",
    "\n",
    "class LabelTransformer(LabelEncoder):\n",
    "    def inverse(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).inverse_transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).inverse_transform([y])\n",
    "\n",
    "    def transform(self, y):\n",
    "        try:\n",
    "            return super(LabelTransformer, self).transform(y)\n",
    "        except:\n",
    "            return super(LabelTransformer, self).transform([y])\n",
    "\n",
    "        \n",
    "class PaddingTransform(object):\n",
    "    def __init__(self, max_length, padding_value=0):\n",
    "        self.max_length = max_length\n",
    "        self.padding_value = padding_value\n",
    "\n",
    "    def __call__(self, s):\n",
    "        if len(s) == self.max_length:\n",
    "            return s\n",
    "\n",
    "        if len(s) > self.max_length:\n",
    "            return s[:self.max_length]\n",
    "\n",
    "        if len(s) < self.max_length:\n",
    "            s1 = copy.deepcopy(s)\n",
    "            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)\n",
    "            s1 = np.vstack((s1, pad))\n",
    "            return s1\n",
    "\n",
    "        \n",
    "class SpectrogramDataset_Test(Dataset):\n",
    "    def __init__(self, path, class_mapping=None, train=True, max_length=-1):\n",
    "        t = 'train' if train else 'test'\n",
    "        p = os.path.join(path, t)\n",
    "        \n",
    "        #self.index = os.path.join(path, \"{}_labels.txt\".format(t))\n",
    "        self.index = p\n",
    "        self.files, labels = self.get_files_labels()\n",
    "        \n",
    "        self.feats = [read_spectrogram(os.path.join(p, f)) for f in self.files]\n",
    "        self.feat_dim = self.feats[0].shape[1]\n",
    "        self.lengths = [len(i) for i in self.feats]\n",
    "        self.max_length = max(self.lengths) if max_length <= 0 else max_length\n",
    "        self.zero_pad_and_stack = PaddingTransform(self.max_length)\n",
    "\n",
    "        self.labels=labels\n",
    "        \n",
    "    def get_files_labels(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        with open(txt, 'r') as fd:\n",
    "            lines = [l.rstrip().split('\\t') for l in fd.readlines()[1:]]\n",
    "            \n",
    "        files, labels = [], []\n",
    "        for l in lines:\n",
    "            l=l[0].split(\",\")\n",
    "            b=l[1:]\n",
    "            b = list(map(float,b))\n",
    "            files.append(l[0])\n",
    "            \n",
    "            labels.append(b)\n",
    "        return files, labels\n",
    "        \"\"\"\n",
    "        files = os.listdir(self.index)\n",
    "        labels=files\n",
    "        return files,labels\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        l = min(self.lengths[item], self.max_length)\n",
    "        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], l\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "52beeba0e3eab3a07c681c7b03caf5a3d5eeef17"
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(SpectrogramDataset_Test('../input/data/data/multitask_dataset/', train=False, class_mapping=class_mapping, max_length=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "aece4f21f2bc967b7eae1e4ed9406d1ef37dbee7"
   },
   "outputs": [],
   "source": [
    "model_cnn_regr_multy3.eval()\n",
    "\n",
    "n_samples = 0\n",
    "SE = 0\n",
    "spearman1=[]\n",
    "spearman2=[]\n",
    "spearman3=[]\n",
    "running_average_loss=0\n",
    "txt=\"solutions_3.txt\"\n",
    "with open(txt, 'w') as fd:\n",
    "    fd.write(\"Id.fused.full.npy.gz,valence,energy,danceability\\n\")\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for index, instance in enumerate(test_loader):\n",
    "            features = instance[:][0].to(device)\n",
    "            label = instance[:][1]\n",
    "            \n",
    "\n",
    "            lengths = instance[:][2].to(device)\n",
    "            features = features.type(torch.FloatTensor).to(device)\n",
    "\n",
    "\n",
    "\n",
    "            out1,out2,out3 = model_cnn_regr_multy3(features,lengths)\n",
    "            out1.to(device)\n",
    "            out2.to(device)\n",
    "            out3.to(device)\n",
    "            \n",
    "            fd.write(label[0]+\",\"+str(out1.item())+\",\"+str(out2.item())+\",\"+str(out3.item())+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "dd72b4d4618812c08843d96b2935f624cae6d82d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb\n",
      "__output__.json\n",
      "solutions_3.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./\"]).decode(\"utf8\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
